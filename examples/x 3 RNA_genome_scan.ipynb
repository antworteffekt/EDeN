{
 "metadata": {
  "name": "",
  "signature": "sha256:af5dd079e98dc95d14c9a52865344935c28bbf3c956a3b357e2b6a894e2ea69d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#RNA genome scan\n",
      "\n",
      "Application scenario: make a model of a set of ncRNA sequences, i.e. a Rfam family, then scan a genome to identify occurences of the family"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import pylab as pl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process( data ):\n",
      "    if hasattr( data, '__iter__' ):\n",
      "        iterable = data\n",
      "    else: #if not then process url or file with fasta_to_fasta\n",
      "        from eden.modifier.fasta import fasta_to_fasta\n",
      "        iterable = fasta_to_fasta( data )\n",
      "        \n",
      "#    from eden.converter.rna.rnafold import rnafold_to_eden\n",
      "#    graphs = rnafold_to_eden( iterable )\n",
      "\n",
      "    from eden.converter.rna.rnashapes import rnashapes_to_eden\n",
      "    graphs = rnashapes_to_eden( iterable , shape_type=5, energy_range=35, max_num=3 )\n",
      "\n",
      "    \n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "def fit_predictive_model(rfam_id, pre_process, n_jobs = 1):\n",
      "    start = time.time()\n",
      "    \n",
      "    from eden.graph import Vectorizer\n",
      "    vectorizer = Vectorizer( r=2, d=2 )\n",
      "\n",
      "    print 'Rfam: %s ' % rfam_id\n",
      "    from eden.modifier.fasta import fasta_to_fasta\n",
      "    graphs = pre_process( rfam_url( rfam_id ) )\n",
      "    X1 = vectorizer.transform( graphs, n_jobs=n_jobs )\n",
      "    print 'Instances: %d ; Features: %d with an avg of %d features per instance' % (X1.shape[0], X1.shape[1],  X1.getnnz()/X1.shape[0])\n",
      "\n",
      "    from eden.modifier.fasta import fasta_to_fasta, shuffle_modifier\n",
      "    graphs = pre_process( fasta_to_fasta( rfam_url( rfam_id ), modifier=shuffle_modifier, times=2, order=2 ) )\n",
      "    X2 = vectorizer.transform( graphs, n_jobs = n_jobs)\n",
      "\n",
      "    from eden.util import fit_estimator\n",
      "    estimator = fit_estimator( positive_data_matrix=X1, negative_data_matrix=X2, cv=5, n_jobs=n_jobs )\n",
      "    \n",
      "    elapsed = (time.time() - start)\n",
      "    print 'Elapsed time: %0.1f sec' % elapsed\n",
      "    \n",
      "    return estimator, vectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "\n",
      "def out_of_core_predictions( iterable, estimator=None, vectorizer=None, threshold=1 ):\n",
      "    iterable_headers, iterable_seqs = itertools.tee( iterable )\n",
      "    \n",
      "    from eden.graph import OutOfCorePredictor\n",
      "    out_of_core_predictor = OutOfCorePredictor( estimator=estimator, vectorizer=vectorizer )\n",
      "\n",
      "    #extract oneline fasta\n",
      "    from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "    headers = fasta_to_fasta( iterable_headers, modifier=one_line_modifier, one_line=True, one_line_separator=' ' )\n",
      "\n",
      "    #extract graphs\n",
      "    graphs = pre_process( iterable_seqs )\n",
      "    predictions = out_of_core_predictor.predict(graphs)\n",
      "\n",
      "    for header, prediction in itertools.izip(headers, predictions):\n",
      "        if prediction >= threshold:\n",
      "            yield header, prediction"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rfam_url(family_id):\n",
      "    '''given the RFAM id of a family we retrieve it from the RFAM online database composing the correspondent URL'''\n",
      "    return 'http://rfam.xfam.org/family/%s/alignment?acc=%s&format=fastau&download=0'%(family_id,family_id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rfam_id = 'RF00005'\n",
      "print rfam_url(rfam_id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://rfam.xfam.org/family/RF00005/alignment?acc=RF00005&format=fastau&download=0\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#extract statistics on the average lenght of the sequences in the given Rfam family\n",
      "import numpy\n",
      "from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "iterable = fasta_to_fasta( rfam_url( rfam_id ), modifier=one_line_modifier, sequence_only=True)\n",
      "len_seqs = [len(seq) for seq in iterable]\n",
      "lower_quantile = int(numpy.percentile(len_seqs, 10))\n",
      "upper_quantile = int(numpy.percentile(len_seqs, 90))\n",
      "\n",
      "num_seqs = len(len_seqs)\n",
      "\n",
      "print 'Rfam family %s has %d sequences' % (rfam_id, num_seqs)\n",
      "print '90 perc of the sequences have lenght smaller than: %d ' % upper_quantile\n",
      "print '10 perc of the sequences have lenght smaller than: %d ' % lower_quantile"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Rfam family RF00005 has 954 sequences\n",
        "90 perc of the sequences have lenght smaller than: 82 \n",
        "10 perc of the sequences have lenght smaller than: 68 \n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "estimator, vectorizer = fit_predictive_model( rfam_id, pre_process, n_jobs=-1 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Rfam: RF00005 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 954 ; Features: 1048577 with an avg of 906 features per instance\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Classifier:\n",
        "SGDClassifier(alpha=2.49730967779e-05, class_weight='auto', epsilon=0.1,\n",
        "       eta0=0.825058958176, fit_intercept=True, l1_ratio=0.15,\n",
        "       learning_rate='constant', loss='hinge', n_iter=99, n_jobs=-1,\n",
        "       penalty='l2', power_t=0.748410157653, random_state=None,\n",
        "       shuffle=True, verbose=0, warm_start=False)\n",
        "-------------------------------------------------------------------------\n",
        "Predictive performance:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "            accuracy: 0.969 +- 0.009\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "           precision: 0.958 +- 0.025\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "              recall: 0.951 +- 0.021\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                  f1: 0.954 +- 0.013\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   average_precision: 0.992 +- 0.006\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             roc_auc: 0.995 +- 0.003\n",
        "-------------------------------------------------------------------------\n",
        "Elapsed time: 327.3 sec\n",
        "CPU times: user 1min 55s, sys: 44.4 s, total: 2min 40s\n",
        "Wall time: 5min 27s\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "select a genome"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genome_fname = 'dm6.fa.masked'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "define an iterator over non masked genome regions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.modifier.fasta import fasta_to_fasta, split_N_modifier\n",
      "iterable = fasta_to_fasta( genome_fname, modifier=split_N_modifier, min_length=lower_quantile )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "...further process the sequences by splitting them with a moving window according to the typical length of the ncRNA that we have modeled"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.modifier.fasta import fasta_to_fasta, split_modifier\n",
      "iterable = fasta_to_fasta( iterable, modifier=split_modifier, window=int(upper_quantile * 6 / 5), step=int(upper_quantile / 5) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "def parse_header(header):\n",
      "    #process header to extract chromosome, start and end position\n",
      "    items = header[1:].split()\n",
      "    chromosome = items[0]\n",
      "    start = int(items[2])+int(items[4])\n",
      "    end = start + int(items[6])\n",
      "    seq = items[7]\n",
      "    id = '%s %d %d %s'%(chromosome,start,end,seq)\n",
      "    return id\n",
      "\n",
      "import sys\n",
      "results = []\n",
      "for header, prediction in out_of_core_predictions( iterable, estimator=estimator, vectorizer=vectorizer, threshold=1 ):\n",
      "    id = parse_header( header )\n",
      "    #save and display results\n",
      "    results.append([id, prediction])\n",
      "    print 'score: %0.1f %s' % (prediction,id)\n",
      "    sys.stdout.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 1.0 chr2L 172076 172174 UAUUUAUUUUAAGCUUGGUUUUAAUUUGGUGCAGAUUAAACAUUGGAAUAGUAAUUUGGUAGUUUCGGUUUAAUUAUUUUUCCUUGCUUCAAUAUAUG\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 1.0 chr2L 504283 504381 UUAAAUAGUUUGGUUGAAAGUAAAUCAAAGUUUCUGAACAUUUGAAGUUGGAAAUGAAAUAAUUCGAUUAAUGAUUAAUUCAUAGACCUCUAAAACAC\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 1.0 chr2L 504299 504397 AAAGUAAAUCAAAGUUUCUGAACAUUUGAAGUUGGAAAUGAAAUAAUUCGAUUAAUGAUUAAUUCAUAGACCUCUAAAACACGUUGCUUGGUGGUUCA\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 1.0 chr2L 504315 504413 UCUGAACAUUUGAAGUUGGAAAUGAAAUAAUUCGAUUAAUGAUUAAUUCAUAGACCUCUAAAACACGUUGCUUGGUGGUUCAACCACCCAAAGUAACA\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 1.0 chr2L 873984 874082 AUGUUAAGUAUUCAAACCUCAAAUCUUGAACGUAUUUAGCUUAGCUUAGCUAUAAGGUAUGUAGAUUCACUUGGCGAGCAGCCCACCUUAAAGACUUA\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 1.3 chr2L 1029536 1029634 AAGAGCUUAGAUAGUUUUAUUUUCCUUGUAUAUCGCAUGAAAUAUUCAUCAUGCAAACUAAUUUGGUUAUUUGGAAAAUAUUUAAGCUACUCCAAGAG\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 1.1 chr2L 1068889 1068987 AUUCAAAUGGCAUGACAUUUCACAUUUGUGGAUGGAAAUUCCGAUUUUAAAUGGAAUUGCUCAAAUUGCAGCCUAAGCUUGGCUCAAAAAAUAAUAGA\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 1.5 chr2L 1305504 1305602 ACUAGUUGUUUAAAAAUAUUUCCCUUUGGCCAAUAUCCGAUUCCCUUUGGGUGUGGAUCAAAGUGCUAAAGCGGAAAUAGUUCAAUCAACUUAGAACG\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 1.4 chr2L 1305520 1305618 UAUUUCCCUUUGGCCAAUAUCCGAUUCCCUUUGGGUGUGGAUCAAAGUGCUAAAGCGGAAAUAGUUCAAUCAACUUAGAACGCCACUCGGCGUGAAGA\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 1.1 chr2L 1659670 1659768 ACUUAAAUGUAUAAAGAUCCUUUCAUAGGAUCUUUAAAGCAAUUAUGAUAGAUACAUUUGUUAACCUUUAAGUUCGAAGUAGAAUAUCUUAAUUUUGC\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 1.1 chr2L 1853683 1853781 UUGUAAUAACUUCAAGCACUUCGCCUUCACAGUGCAGAAGAUAUAUUGUUUGUAAUUUAUCUUAAGCCUUAGCUUGUAAGUAAACUUGAAAAUUUACG\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 1.1 chr2L 2095518 2095616 GGCUUAAAAACUUCAGGCUUGGGUCUUUAGAAGCACACAUGGUGUUUUAAAACAUUAGAAAUGGUUUUCUAAGCAAAUAAAGCUAAAGCCUUCAAUUC\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 1.2 chr2L 2203665 2203763 GAUUCAAUCUUGAAAUUUUAAAUAUUCAACUUGUUUAAUACUUUCUAAGAUAUUUAAAAGAUGAUUCCCCAAAUGUUAGUUAGUUGGUUAAACAUUUA\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 1.5 chr2L 2462586 2462684 UAUAGACCUUCGAUAGCUCAGUUGGUAGAGCGGUGGACUGUAGAUUGGGAUUACGAAUGUAGACAUCCAUAGGUCGCUGGUUCAAAUCCGGCUCGAAG\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 1.2 chr2L 2495498 2495596 AUCCGAGGCUCUAGAGAGCAGGGCGAGAGACCCAAUUGAAAUUGAAAACCUCUUAUCCAUCUUCCCCUCAGGAGGUUCAAAUCCUCAAGGCUCUGGUU\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 1.2 chr2L 2594734 2594832 AGGAAUCUGCAGAGGGAAAUAAACUUAAGUGCAGCAGCCACGUUGCCGAGUUCCAAAGGAACUCGAUUCGAAACGACUUGGUUCCAUUCGAAAUUUGA\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 1.0 chr2L 3135989 3136087 GUUGGUGGCUUAAAAUAAUGCUUGGCUUUCUGAACAGAAAUAAUUGCAUUAAAAUUCUGAAAGUUCGAAUUUUAAACUAAUCUAGUUAAUAAGCCAUU\n"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#idea: annotate training set, extract max subarray motives of size > k, eliminate those that appear in negative set, \n",
      "#build an OR pattern matching regex \n",
      "#split with windows, then accept only if regex matches \n",
      "#then give to EDeN model\n",
      "\n",
      "#also, to be more precise: annotate instances and learn a model over the re-weighted instances\n",
      "\n",
      "#save a trained model! so not to have to recompute it every time!\n",
      "\n",
      "#print the results to file!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}