{
 "metadata": {
  "name": "",
  "signature": "sha256:292470b30b5e3f96ee36082a761a4acde744807d2bde8dd37964196a32e9486d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#RNA genome scan\n",
      "\n",
      "Application scenario: make a model of a set of ncRNA sequences, i.e. a Rfam family, then scan a genome to identify occurences of the family"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import pylab as pl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.sparse import vstack\n",
      "import numpy as np\n",
      "\n",
      "def make_data_matrix(X1,X2):\n",
      "    #create target array\n",
      "    yp =  [1] * X1.shape[0]\n",
      "    yn = [-1] * X2.shape[0]\n",
      "    y = np.array(yp + yn)\n",
      "    #update data matrix\n",
      "    X = vstack( [X1,X2] , format = \"csr\")\n",
      "    return X,y\n",
      "\n",
      "\n",
      "def make_iterable( data ):\n",
      "    #check if data is iterable\n",
      "    if hasattr( data, '__iter__' ):\n",
      "        iterable = data\n",
      "    else: #if not then process url or file with fasta_to_fasta\n",
      "        from eden.modifier.fasta import fasta_to_fasta\n",
      "        iterable = fasta_to_fasta( data )\n",
      "    return iterable"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process( data ):\n",
      "    iterable = make_iterable( data )\n",
      "    \n",
      "    from eden.converter.rna.rnafold import rnafold_to_eden\n",
      "    graphs = rnafold_to_eden( iterable )\n",
      "    \n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "def fit_predictive_model(rfam_id, pre_process, n_jobs = 1):\n",
      "    start = time.time()\n",
      "    \n",
      "    from eden.graph import Vectorizer\n",
      "    vectorizer = Vectorizer( r = 1, d = 1 )\n",
      "\n",
      "    print 'Rfam: %s ' % rfam_id\n",
      "    from eden.modifier.fasta import fasta_to_fasta\n",
      "    graphs = pre_process( rfam_url( rfam_id ) )\n",
      "    X1 = vectorizer.transform( graphs, n_jobs = n_jobs )\n",
      "    print 'Instances: %d ; Features: %d with an avg of %d features per instance' % (X1.shape[0], X1.shape[1],  X1.getnnz()/X1.shape[0])\n",
      "\n",
      "    from eden.modifier.fasta import fasta_to_fasta, shuffle_modifier\n",
      "    graphs = pre_process( fasta_to_fasta( rfam_url( rfam_id ), modifier = shuffle_modifier, times = 2, order = 2 ) )\n",
      "    X2 = vectorizer.transform( graphs, n_jobs = n_jobs)\n",
      "\n",
      "    \n",
      "    from eden.util import estimate_predictive_performance\n",
      "    X,y = make_data_matrix( X1, X2 )\n",
      "    estimator = estimate_predictive_performance( X, y , cv = 5, n_jobs = n_jobs)\n",
      "    \n",
      "    elapsed = (time.time() - start)\n",
      "    print 'Elapsed time: %0.1f sec' % elapsed\n",
      "    \n",
      "    return estimator, vectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "\n",
      "def out_of_core_predictions( data, estimator = None, vectorizer = None, threshold = 1 ):\n",
      "    iterable = make_iterable(data)\n",
      "    iterable_headers, iterable_seqs = itertools.tee( iterable )\n",
      "    \n",
      "    from eden.graph import OutOfCorePredictor\n",
      "    out_of_core_predictor = OutOfCorePredictor( estimator = estimator, vectorizer = vectorizer )\n",
      "\n",
      "    #extract oneline fasta\n",
      "    from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "    headers = fasta_to_fasta( iterable_headers, modifier = one_line_modifier, header_only = True )\n",
      "\n",
      "    #extract graphs\n",
      "    graphs = pre_process( iterable_seqs )\n",
      "    predictions = out_of_core_predictor.predict(graphs)\n",
      "\n",
      "    for header, prediction in itertools.izip(headers, predictions):\n",
      "        if prediction >= threshold:\n",
      "            yield header, prediction"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#given the RFAM id of a family we retrieve it from the RFAM online database composing the correspondent URL\n",
      "\n",
      "def rfam_url(family_id):\n",
      "    return 'http://rfam.xfam.org/family/%s/alignment?acc=%s&format=fastau&download=0'%(family_id,family_id)\n",
      "\n",
      "rfam_id = 'RF00005'\n",
      "print rfam_url(rfam_id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://rfam.xfam.org/family/RF00005/alignment?acc=RF00005&format=fastau&download=0\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "iterable = fasta_to_fasta( rfam_url( rfam_id ) , modifier = one_line_modifier, sequence_only = True)\n",
      "len_seqs = [len(seq) for seq in iterable]\n",
      "lower_quantile = int(numpy.percentile(len_seqs, 10))\n",
      "upper_quantile = int(numpy.percentile(len_seqs, 90))\n",
      "\n",
      "num_seqs = len(len_seqs)\n",
      "\n",
      "print 'Rfam family %s has %d sequences' % (rfam_id, num_seqs)\n",
      "print '90 perc of the sequences have lenght smaller than: %d ' % upper_quantile\n",
      "print '10 perc of the sequences have lenght smaller than: %d ' % lower_quantile"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Rfam family RF00005 has 954 sequences\n",
        "90 perc of the sequences have lenght smaller than: 82 \n",
        "10 perc of the sequences have lenght smaller than: 68 \n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "estimator, vectorizer = fit_predictive_model( rfam_id, pre_process )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Rfam: RF00005 \n",
        "Instances: 954 ; Features: 1048577 with an avg of 138 features per instance"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Classifier:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "SGDClassifier(alpha=8.71709484924e-05, class_weight='auto', epsilon=0.1,\n",
        "       eta0=2.61562031424, fit_intercept=True, l1_ratio=0.15,\n",
        "       learning_rate='optimal', loss='hinge', n_iter=37, n_jobs=1,\n",
        "       penalty='elasticnet', power_t=0.523338972649, random_state=None,\n",
        "       shuffle=True, verbose=0, warm_start=False)\n",
        "-------------------------------------------------------------------------\n",
        "Predictive performance:\n",
        "            accuracy: 0.944 +- 0.008"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "           precision: 0.916 +- 0.028"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "              recall: 0.939 +- 0.024"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "                  f1: 0.917 +- 0.013"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "   average_precision: 0.973 +- 0.009"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "             roc_auc: 0.983 +- 0.005"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-------------------------------------------------------------------------\n",
        "Elapsed time: 113.6 sec\n",
        "CPU times: user 1min 14s, sys: 10.2 s, total: 1min 24s\n",
        "Wall time: 1min 53s\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "create a modifier that splits sequences on the occurrences of repeated N symbols "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split_N_modifier(header = None, seq = None, **options):\n",
      "    min_length =  options.get('min_length',10)\n",
      "    seq_curr = ''\n",
      "    start = 0\n",
      "    for i,c in enumerate(seq):\n",
      "        if c != 'N':\n",
      "            if c == 'T':\n",
      "                l = 'U'\n",
      "            else:\n",
      "                l = c\n",
      "            seq_curr += l\n",
      "        else:\n",
      "            if len(seq_curr) >= min_length:\n",
      "                yield '%s START: %0.9d' % (header, start + 1 )\n",
      "                yield seq_curr\n",
      "            seq_curr = ''\n",
      "            start = i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "select a genome"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genome_fname = 'dm6.fa.masked'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "define an iterator over non masked genome regions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.modifier.fasta import fasta_to_fasta\n",
      "iterable = fasta_to_fasta( genome_fname, modifier = split_N_modifier, min_length = lower_quantile )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "...further process the sequences by splitting them with a moving window according to the typical length of the ncRNA that we have modeled"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.modifier.fasta import fasta_to_fasta, split_modifier\n",
      "iterable = fasta_to_fasta( iterable, modifier = split_modifier, window = upper_quantile, step = int(upper_quantile / 3) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "def parse_header(header):\n",
      "    #process header to extract chromosome, start and end position\n",
      "    items = header[1:].split()\n",
      "    chromosome = items[0]\n",
      "    start = int(items[2])+int(items[4])\n",
      "    end = start + int(items[6])\n",
      "    id = '%s %d %d'%(chromosome, start,end)\n",
      "    return id\n",
      "\n",
      "import sys\n",
      "results = []\n",
      "for header, prediction in out_of_core_predictions( iterable, estimator = estimator, vectorizer = vectorizer, threshold = 1.5 ):\n",
      "    id = parse_header( header )\n",
      "    #save and display results\n",
      "    results.append([id, prediction])\n",
      "    print '%0.30s  confidence: %0.1f' % (id, prediction)\n",
      "    sys.stdout.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 15744 15826  confidence: 1.7\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 15955 16037  confidence: 1.7\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 96331 96413  confidence: 1.8\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 251990 252072  confidence: 1.5\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 272898 272980  confidence: 1.6\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 301874 301956  confidence: 1.5\n"
       ]
      }
     ]
    }
   ],
   "metadata": {}
  }
 ]
}