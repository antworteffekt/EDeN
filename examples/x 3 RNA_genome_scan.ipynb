{
 "metadata": {
  "name": "",
  "signature": "sha256:a89d5dd27c13feec6645bb2ec901ce72cbfd87648b875d41fb98682bd77f7b52"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#RNA genome scan\n",
      "\n",
      "Application scenario: make a model of a set of ncRNA sequences, i.e. a Rfam family, then scan a genome to identify occurences of the family"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import pylab as pl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_iterable( data ):\n",
      "    #check if data is iterable\n",
      "    if hasattr( data, '__iter__' ):\n",
      "        iterable = data\n",
      "    else: #if not then process url or file with fasta_to_fasta\n",
      "        from eden.modifier.fasta import fasta_to_fasta\n",
      "        iterable = fasta_to_fasta( data )\n",
      "    return iterable"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process( data ):\n",
      "    iterable = make_iterable( data )\n",
      "    \n",
      "    from eden.converter.rna.rnafold import rnafold_to_eden\n",
      "    graphs = rnafold_to_eden( iterable )\n",
      "    \n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "def fit_predictive_model(rfam_id, pre_process, n_jobs = 1):\n",
      "    start = time.time()\n",
      "    \n",
      "    from eden.graph import Vectorizer\n",
      "    vectorizer = Vectorizer( r=1, d=1 )\n",
      "\n",
      "    print 'Rfam: %s ' % rfam_id\n",
      "    from eden.modifier.fasta import fasta_to_fasta\n",
      "    graphs = pre_process( rfam_url( rfam_id ) )\n",
      "    X1 = vectorizer.transform( graphs, n_jobs=n_jobs )\n",
      "    print 'Instances: %d ; Features: %d with an avg of %d features per instance' % (X1.shape[0], X1.shape[1],  X1.getnnz()/X1.shape[0])\n",
      "\n",
      "    from eden.modifier.fasta import fasta_to_fasta, shuffle_modifier\n",
      "    graphs = pre_process( fasta_to_fasta( rfam_url( rfam_id ), modifier=shuffle_modifier, times=2, order=2 ) )\n",
      "    X2 = vectorizer.transform( graphs, n_jobs = n_jobs)\n",
      "\n",
      "    from eden.util import fit_estimator\n",
      "    estimator = fit_estimator( positive_data_matrix=X1, negative_data_matrix=X2, cv=5, n_jobs=n_jobs )\n",
      "    \n",
      "    elapsed = (time.time() - start)\n",
      "    print 'Elapsed time: %0.1f sec' % elapsed\n",
      "    \n",
      "    return estimator, vectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "\n",
      "def out_of_core_predictions( data, estimator=None, vectorizer=None, threshold=1 ):\n",
      "    iterable = make_iterable(data)\n",
      "    iterable_headers, iterable_seqs = itertools.tee( iterable )\n",
      "    \n",
      "    from eden.graph import OutOfCorePredictor\n",
      "    out_of_core_predictor = OutOfCorePredictor( estimator=estimator, vectorizer=vectorizer )\n",
      "\n",
      "    #extract oneline fasta\n",
      "    from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "    headers = fasta_to_fasta( iterable_headers, modifier=one_line_modifier, header_only=True )\n",
      "\n",
      "    #extract graphs\n",
      "    graphs = pre_process( iterable_seqs )\n",
      "    predictions = out_of_core_predictor.predict(graphs)\n",
      "\n",
      "    for header, prediction in itertools.izip(headers, predictions):\n",
      "        if prediction >= threshold:\n",
      "            yield header, prediction"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rfam_url(family_id):\n",
      "    '''given the RFAM id of a family we retrieve it from the RFAM online database composing the correspondent URL'''\n",
      "    return 'http://rfam.xfam.org/family/%s/alignment?acc=%s&format=fastau&download=0'%(family_id,family_id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://rfam.xfam.org/family/RF00005/alignment?acc=RF00005&format=fastau&download=0\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rfam_id = 'RF00005'\n",
      "print rfam_url(rfam_id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://rfam.xfam.org/family/RF00005/alignment?acc=RF00005&format=fastau&download=0\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#extract statistics on the average lenght of the sequences in the given Rfam family\n",
      "import numpy\n",
      "from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "iterable = fasta_to_fasta( rfam_url( rfam_id ), modifier=one_line_modifier, sequence_only=True)\n",
      "len_seqs = [len(seq) for seq in iterable]\n",
      "lower_quantile = int(numpy.percentile(len_seqs, 10))\n",
      "upper_quantile = int(numpy.percentile(len_seqs, 90))\n",
      "\n",
      "num_seqs = len(len_seqs)\n",
      "\n",
      "print 'Rfam family %s has %d sequences' % (rfam_id, num_seqs)\n",
      "print '90 perc of the sequences have lenght smaller than: %d ' % upper_quantile\n",
      "print '10 perc of the sequences have lenght smaller than: %d ' % lower_quantile"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Rfam family RF00005 has 954 sequences\n",
        "90 perc of the sequences have lenght smaller than: 82 \n",
        "10 perc of the sequences have lenght smaller than: 68 \n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "estimator, vectorizer = fit_predictive_model( rfam_id, pre_process )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Rfam: RF00005 \n",
        "Instances: 954 ; Features: 1048577 with an avg of 138 features per instance"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Classifier:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "SGDClassifier(alpha=6.13697976336e-05, class_weight='auto', epsilon=0.1,\n",
        "       eta0=6.93125306436, fit_intercept=True, l1_ratio=0.15,\n",
        "       learning_rate='optimal', loss='hinge', n_iter=89, n_jobs=1,\n",
        "       penalty='elasticnet', power_t=0.718460387184, random_state=None,\n",
        "       shuffle=True, verbose=0, warm_start=False)\n",
        "-------------------------------------------------------------------------\n",
        "Predictive performance:\n",
        "            accuracy: 0.941 +- 0.018"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "           precision: 0.890 +- 0.036"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "              recall: 0.929 +- 0.014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "                  f1: 0.905 +- 0.025"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "   average_precision: 0.973 +- 0.010"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "             roc_auc: 0.982 +- 0.006"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-------------------------------------------------------------------------\n",
        "Elapsed time: 204.1 sec\n",
        "CPU times: user 1min 32s, sys: 8.14 s, total: 1min 40s\n",
        "Wall time: 3min 24s\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "select a genome"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genome_fname = 'dm6.fa.masked'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "define an iterator over non masked genome regions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.modifier.fasta import fasta_to_fasta, split_N_modifier\n",
      "iterable = fasta_to_fasta( genome_fname, modifier=split_N_modifier, min_length=lower_quantile )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "...further process the sequences by splitting them with a moving window according to the typical length of the ncRNA that we have modeled"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.modifier.fasta import fasta_to_fasta, split_modifier\n",
      "iterable = fasta_to_fasta( iterable, modifier=split_modifier, window=int(upper_quantile * 6 / 5), step=int(upper_quantile / 5) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "def parse_header(header):\n",
      "    #process header to extract chromosome, start and end position\n",
      "    items = header[1:].split()\n",
      "    chromosome = items[0]\n",
      "    start = int(items[2])+int(items[4])\n",
      "    end = start + int(items[6])\n",
      "    id = '%s %d %d'%(chromosome,start,end)\n",
      "    return id\n",
      "\n",
      "import sys\n",
      "results = []\n",
      "for header, prediction in out_of_core_predictions( iterable, estimator=estimator, vectorizer=vectorizer, threshold=2 ):\n",
      "    id = parse_header( header )\n",
      "    #save and display results\n",
      "    results.append([id, prediction])\n",
      "    print '%0.40s  confidence: %0.1f' % (id, prediction)\n",
      "    sys.stdout.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 1305504 1305602  confidence: 2.8\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 1305520 1305618  confidence: 2.6\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 1375485 1375583  confidence: 2.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 1925757 1925855  confidence: 2.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 1947564 1947662  confidence: 2.5\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 2594734 2594832  confidence: 2.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 2782911 2783009  confidence: 2.2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 2802604 2802702  confidence: 2.4\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 3135989 3136087  confidence: 2.4\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 3400020 3400118  confidence: 2.3\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 4074765 4074863  confidence: 2.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 4589865 4589963  confidence: 2.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 4825179 4825277  confidence: 2.3\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 5703186 5703284  confidence: 3.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 6488774 6488872  confidence: 2.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 6696283 6696381  confidence: 2.2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 6793417 6793515  confidence: 2.5\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 6887443 6887541  confidence: 2.2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 7536569 7536667  confidence: 2.2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 7552263 7552361  confidence: 2.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 7637729 7637827  confidence: 2.3\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 7895394 7895492  confidence: 2.3\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 7941920 7942018  confidence: 2.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 8129738 8129836  confidence: 2.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 8165798 8165896  confidence: 2.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 9020319 9020417  confidence: 2.3\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 9657452 9657550  confidence: 2.3\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 9657532 9657630  confidence: 2.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 9716405 9716503  confidence: 2.7\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 9716437 9716535  confidence: 3.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 10036380 10036478  confidence: 2.2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 11183843 11183941  confidence: 2.7\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 11575899 11575997  confidence: 2.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 11819016 11819114  confidence: 2.4\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 11819032 11819130  confidence: 2.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 11999401 11999499  confidence: 2.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 12047149 12047247  confidence: 2.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 12477801 12477899  confidence: 2.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 12479902 12480000  confidence: 2.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 13034026 13034124  confidence: 2.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 13055311 13055409  confidence: 2.3\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 13055327 13055425  confidence: 2.8\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 13092154 13092252  confidence: 2.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 13250438 13250536  confidence: 2.2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 13587276 13587374  confidence: 2.4\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 14235583 14235681  confidence: 2.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 14876244 14876342  confidence: 2.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 15203137 15203235  confidence: 2.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 15869034 15869132  confidence: 2.2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 15895232 15895330  confidence: 2.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 15964091 15964189  confidence: 2.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 16504152 16504250  confidence: 2.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 16767667 16767765  confidence: 2.2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 16780994 16781092  confidence: 2.4\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chr2L 16945299 16945397  confidence: 2.0\n"
       ]
      }
     ]
    }
   ],
   "metadata": {}
  }
 ]
}