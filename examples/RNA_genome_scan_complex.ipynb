{
 "metadata": {
  "name": "",
  "signature": "sha256:b78924da121fdad61e58c26f20baec0c83f0e96ffceec1d91a08822a96cb7053"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%reload_ext autoreload"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "\n",
      "def join_pre_processes( data, pre_processes, weights):\n",
      "    if hasattr( data, '__iter__' ):\n",
      "        iterable = data\n",
      "    else: #if not then process url or file with fasta_to_fasta\n",
      "        from eden.modifier.fasta import fasta_to_fasta\n",
      "        iterable = fasta_to_fasta( data )\n",
      "        \n",
      "    graphs_list = list()\n",
      "    assert(len(weights) == len(pre_processes)),'Different lengths'\n",
      "    #NOTE: we have to duplicate the sequences iterator if we want to use different modifiers in parallel\n",
      "    iterables = itertools.tee( iterable, len(pre_processes) )\n",
      "    for pre_process_item, iterable_item in zip(pre_processes, iterables):\n",
      "        graphs_list.append( pre_process_item( iterable_item ) )\n",
      "    return (graphs_list, weights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_rnashapes( iterable ):\n",
      "    from eden.converter.rna.rnashapes import rnashapes_to_eden\n",
      "    graphs = rnashapes_to_eden( iterable, shape_type = 5, energy_range = 35, max_num = 3 )\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_fasta( iterable ):\n",
      "    from eden.converter.fasta import fasta_to_eden\n",
      "    graphs = fasta_to_eden( iterable )\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_structure( iterable ):\n",
      "    from eden.converter.rna.rnashapes_struct import rnashapes_struct_to_eden\n",
      "    graphs = rnashapes_struct_to_eden(iterable, shape=True, dotbracket=False, energy=False, shape_type=5, energy_range=35, max_num=3)\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_energy( iterable ):\n",
      "    from eden.converter.rna.rnashapes_struct import rnashapes_struct_to_eden\n",
      "    graphs = rnashapes_struct_to_eden(iterable, energy=True, dotbracket=False, shape=False, shape_type=5, energy_range=35, max_num=3)\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_contraction( iterable ):\n",
      "    from eden.converter.rna.rnashapes import rnashapes_to_eden\n",
      "    graphs = rnashapes_to_eden( iterable, shape_type=5, energy_range=35, max_num=3 )\n",
      "    \n",
      "    #annotate in node attribute 'type' the incident edges' labels\n",
      "    from eden.modifier.graph import vertex_attributes\n",
      "    graphs = vertex_attributes.incident_edge_label(graphs, level=1, output_attribute='type', separator='.')\n",
      "    \n",
      "    from eden.modifier.graph.structure import contraction, contraction_modifier\n",
      "    label_modifier = contraction_modifier(attribute_in='type', attribute_out='label', reduction='set_categorical')\n",
      "    \n",
      "    #reduce all 'weight' attributes of contracted nodes using a sum to be written in the 'weight' attribute of the resulting graph \n",
      "    weight_modifier = contraction_modifier(attribute_in='weight', attribute_out='weight', reduction='sum')\n",
      "    modifiers = [label_modifier, weight_modifier]\n",
      "    \n",
      "    #contract the graph on the 'type' attribute\n",
      "    graphs = contraction(graphs, contraction_attribute='type', modifiers=modifiers)\n",
      "    \n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process( data ):\n",
      "    pre_processes = [pre_process_energy, pre_process_rnashapes, pre_process_fasta, pre_process_structure, pre_process_contraction]\n",
      "    weights = [0.4, 0.2, 0.05, 0.3, 0.05]\n",
      "    return join_pre_processes( data, pre_processes, weights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process( data ):\n",
      "    pre_processes = [pre_process_energy, pre_process_structure]\n",
      "    weights = [0.2, 0.8]\n",
      "    return join_pre_processes( data, pre_processes, weights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def describe(X):\n",
      "    print 'Instances: %d ; Features: %d (with an avg of %d features per instance)' % (X.shape[0], X.shape[1],  X.getnnz()/X.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def model(uri, pre_process):\n",
      "\n",
      "    from eden.graph import Vectorizer\n",
      "    vectorizer = Vectorizer( r=2, d=2 )\n",
      "    n_jobs = 1\n",
      "\n",
      "    graphs = pre_process( uri )\n",
      "    X1 = vectorizer.transform( graphs, n_jobs=n_jobs )\n",
      "    describe(X1)\n",
      "    \n",
      "    from eden.modifier.fasta import fasta_to_fasta, shuffle_modifier\n",
      "    graphs = pre_process( fasta_to_fasta( uri , modifier=shuffle_modifier, times=2, order=2) )\n",
      "    X2 = vectorizer.transform( graphs, n_jobs=n_jobs )\n",
      "    describe(X2)\n",
      "    \n",
      "    from eden.util import fit_estimator\n",
      "    estimator = fit_estimator( positive_data_matrix=X1, negative_data_matrix=X2, cv=5 )\n",
      "    \n",
      "    return estimator, vectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def list_model(uri, pre_process):\n",
      "\n",
      "    from eden.graph import ListVectorizer\n",
      "    vectorizer = ListVectorizer( r=2, d=2 )\n",
      "    n_jobs = -1\n",
      "\n",
      "    graphs_list, weights = pre_process( uri )\n",
      "    X1 = vectorizer.transform( graphs_list, weights=weights, n_jobs=n_jobs )\n",
      "    describe(X1)\n",
      "    \n",
      "    from eden.modifier.fasta import fasta_to_fasta, shuffle_modifier\n",
      "    graphs_list, weights = pre_process( fasta_to_fasta( uri , modifier=shuffle_modifier, times=2, order=2) )\n",
      "    X2 = vectorizer.transform( graphs_list, weights=weights, n_jobs=n_jobs )\n",
      "    describe(X2)\n",
      "    \n",
      "    from eden.util import fit_estimator\n",
      "    estimator = fit_estimator( positive_data_matrix=X1, negative_data_matrix=X2, cv=5 )\n",
      "    \n",
      "    return estimator, vectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rfam_url(family_id):\n",
      "    return 'http://rfam.xfam.org/family/%s/alignment?acc=%s&format=fastau&download=0'%(family_id,family_id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rfam_id = 'RF00005' #tRNA"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rfam_id = 'RF00871' #microRNA mir-689"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "estimator, vectorizer = model(rfam_url( rfam_id ), pre_process_rnashapes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 13 ; Features: 1048577 with an avg of 986 features per instance\n",
        "Instances: 26 ; Features: 1048577 with an avg of 1162 features per instance"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Classifier:\n",
        "SGDClassifier(alpha=0.000692896161219, class_weight='auto', epsilon=0.1,\n",
        "       eta0=2.17005352922, fit_intercept=True, l1_ratio=0.15,\n",
        "       learning_rate='invscaling', loss='hinge', n_iter=98, n_jobs=-1,\n",
        "       penalty='l1', power_t=0.503783806427, random_state=None,\n",
        "       shuffle=True, verbose=0, warm_start=False)\n",
        "-------------------------------------------------------------------------\n",
        "Predictive performance:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "            accuracy: 1.000 +- 0.000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "           precision: 1.000 +- 0.000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "              recall: 1.000 +- 0.000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                  f1: 1.000 +- 0.000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   average_precision: 1.000 +- 0.000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             roc_auc: 1.000 +- 0.000\n",
        "-------------------------------------------------------------------------\n",
        "CPU times: user 7.1 s, sys: 715 ms, total: 7.82 s\n",
        "Wall time: 36.1 s\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "estimator_str, vectorizer_str = list_model(rfam_url( rfam_id ), pre_process)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 13 ; Features: 1048577 with an avg of 117 features per instance\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 26 ; Features: 1048577 with an avg of 129 features per instance\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Classifier:\n",
        "SGDClassifier(alpha=7.18454013193e-05, class_weight='auto', epsilon=0.1,\n",
        "       eta0=4.5623730378, fit_intercept=True, l1_ratio=0.15,\n",
        "       learning_rate='optimal', loss='hinge', n_iter=63, n_jobs=-1,\n",
        "       penalty='elasticnet', power_t=0.437635232221, random_state=None,\n",
        "       shuffle=True, verbose=0, warm_start=False)\n",
        "-------------------------------------------------------------------------\n",
        "Predictive performance:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "            accuracy: 0.896 +- 0.095\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "           precision: 0.933 +- 0.133\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "              recall: 0.767 +- 0.200\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                  f1: 0.827 +- 0.150\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   average_precision: 0.903 +- 0.194\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             roc_auc: 0.960 +- 0.080\n",
        "-------------------------------------------------------------------------\n",
        "CPU times: user 1.18 s, sys: 468 ms, total: 1.65 s\n",
        "Wall time: 46.3 s\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_motives(uri, motif_support_threshold = 2, min_subarray_size=5, max_subarray_size=18, estimator = estimator, vectorizer = vectorizer):\n",
      "    from eden.graph import Annotator\n",
      "    annotator = Annotator( estimator = estimator, vectorizer = vectorizer )\n",
      "\n",
      "    #annotate graphs with node importance \n",
      "    graphs = pre_process_rnashapes( uri )\n",
      "    graphs = annotator.transform( graphs )\n",
      "\n",
      "    #use node importance and 'position' attribute to identify max_subarrays of a specific size\n",
      "    #use compute_max_subarrays to return an iterator over motives \n",
      "    from eden.util.iterated_maximum_subarray import compute_max_subarrays\n",
      "\n",
      "    motives = set()\n",
      "    for graph in graphs:\n",
      "        subarrays = compute_max_subarrays(graph=graph, min_subarray_size=min_subarray_size, max_subarray_size=max_subarray_size)\n",
      "        if subarrays:\n",
      "            for subarray in subarrays:\n",
      "                motives.add(''.join(subarray['subarray']))    \n",
      "    \n",
      "    #count occurrences of motives in original dataset to determine support of each motif\n",
      "    from collections import defaultdict\n",
      "\n",
      "    from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "    iterable = fasta_to_fasta( uri, modifier=one_line_modifier, sequence_only=True)\n",
      "\n",
      "    motif_counter = defaultdict(int)\n",
      "    for seq in iterable:\n",
      "        for motif in motives:\n",
      "            if seq.find(motif) != -1:\n",
      "                motif_counter[motif] += 1\n",
      "    \n",
      "    #select only motives with support higher than a user defined threshold\n",
      "    selcted_motives = [motif for motif in motif_counter if motif_counter[motif] >= motif_support_threshold]   \n",
      "\n",
      "    #remove motives that are specializations of smaller motifs\n",
      "    blacklist=set()\n",
      "    for motif1 in selcted_motives:\n",
      "        for motif2 in selcted_motives:\n",
      "            if motif1 != motif2 and motif1 in motif2:\n",
      "                blacklist.add(motif2)\n",
      "    selcted_motives=list(set(selcted_motives).difference(blacklist))\n",
      "    \n",
      "    #build a regex expression that matches the occurrence of at least one of the motives\n",
      "    regex=''\n",
      "    for m in sorted(selcted_motives): regex += '|' + m\n",
      "    regex = regex[1:]\n",
      "    return regex"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "regex = extract_motives(rfam_url( rfam_id ), motif_support_threshold = 2, min_subarray_size=5, max_subarray_size=18, estimator = estimator, vectorizer = vectorizer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def motives_discriminative_performance_evaluation(data, regex):\n",
      "    #compute statistics when using the motives as indicators for the target family on the original data \n",
      "    #and on a randomly permuted dataset\n",
      "    \n",
      "    from eden.modifier.fasta import fasta_to_fasta, keep_modifier, shuffle_modifier\n",
      "    iterable = fasta_to_fasta( data , modifier=keep_modifier, regex=regex )\n",
      "    true_positive_count = sum(1 for x in iterable)\n",
      "    iterable = fasta_to_fasta( data )\n",
      "    positive_count = sum(1 for x in iterable)\n",
      "    iterable = fasta_to_fasta( data , modifier=shuffle_modifier, times=20, order=2)\n",
      "    it1,it2 = itertools.tee(iterable)\n",
      "    negative_count = sum(1 for x in it1)\n",
      "    iterable = fasta_to_fasta( it2 , modifier=keep_modifier, regex=regex )\n",
      "    false_positive_count = sum(1 for x in iterable)\n",
      "    false_negative_count =  positive_count - true_positive_count\n",
      "    true_negative_count = negative_count - false_negative_count\n",
      "\n",
      "    recall = true_positive_count/float(true_positive_count + false_negative_count)\n",
      "    precision = true_positive_count/float(true_positive_count + false_positive_count)\n",
      "    f1 = 2 * precision * recall / (precision + recall)\n",
      "\n",
      "    print 'pos:%d neg:%d TP:%d FP:%d TN:%d FN:%d' % (positive_count, negative_count, true_positive_count, false_positive_count, true_negative_count, false_negative_count)\n",
      "    print 'precision:%0.3f recall:%0.3f f1:%0.3f' % (precision, recall, f1)\n",
      "    print 'dataset reduction: from %d to %d = %0.3f' % (negative_count, false_positive_count, false_positive_count/float(negative_count))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "motives_discriminative_performance_evaluation(rfam_url( rfam_id ), regex)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "pos:26 neg:520 TP:22 FP:2 TN:516 FN:4\n",
        "precision:0.917 recall:0.846 f1:0.880\n",
        "dataset reduction: from 520 to 2 = 0.004\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def lenght_stats(uri, lower_percentile=25, upper_percentile=75):\n",
      "    #extract statistics on the average lenght of the sequences in the given Rfam family\n",
      "    #use this information to determine the size of the window when scanning the genome\n",
      "    import numpy\n",
      "    from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "\n",
      "    iterable = fasta_to_fasta( uri, modifier=one_line_modifier, sequence_only=True)\n",
      "    len_seqs = [len(seq) for seq in iterable]\n",
      "    lower_quantile = int(numpy.percentile(len_seqs, lower_percentile))\n",
      "    upper_quantile = int(numpy.percentile(len_seqs, upper_percentile))\n",
      "\n",
      "    num_seqs = len(len_seqs)\n",
      "\n",
      "    print 'Rfam family %s has %d sequences' % (rfam_id, num_seqs)\n",
      "    print 'more than %d%% of the sequences have lenght smaller than: %d ' % (upper_percentile, upper_quantile)\n",
      "    print 'less then %d%% of the sequences have lenght smaller than: %d ' % (lower_percentile, lower_quantile)\n",
      "    \n",
      "    return lower_quantile, upper_quantile"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lower_quantile, upper_quantile = lenght_stats(rfam_url( rfam_id ), lower_percentile=25, upper_percentile=75)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Rfam family RF00871 has 13 sequences\n",
        "more than 75% of the sequences have lenght smaller than: 111 \n",
        "less then 25% of the sequences have lenght smaller than: 102 \n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def out_of_core_list_filter( iterable, estimator=None, vectorizer=None, pre_process=None, threshold=1 ):\n",
      "    #define a filter that uses the predictive model\n",
      "    import itertools\n",
      "    iterable_headers, iterable_seqs = itertools.tee( iterable )\n",
      "    \n",
      "    #1. extract oneline fasta\n",
      "    from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "    header_seqs = fasta_to_fasta( iterable_headers, modifier=one_line_modifier, one_line=True )\n",
      "\n",
      "    #2. extract graphs\n",
      "    graphs_list, weights = pre_process( iterable_seqs )\n",
      "    from eden.graph import OutOfCoreListPredictor\n",
      "    out_of_core_list_predictor = OutOfCoreListPredictor( estimator=estimator, vectorizer=vectorizer )\n",
      "    predictions = out_of_core_list_predictor.predict(graphs_list, weights=weights)\n",
      "\n",
      "    #1+2\n",
      "    for header_seq, prediction in itertools.izip(header_seqs, predictions):\n",
      "        if prediction >= threshold:\n",
      "            lines = header_seq.split('\\t')\n",
      "            header = lines[0] + ' SCORE: %.3f '%prediction\n",
      "            seq = lines[1]\n",
      "            yield header\n",
      "            yield seq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#parameters choice\n",
      "uri = 'dm6.fa.masked'\n",
      "min_lenght = lower_quantile\n",
      "max_lenght = upper_quantile\n",
      "threshold = 1\n",
      "pre_process = pre_process\n",
      "estimator = estimator_str\n",
      "vectorizer = vectorizer_str\n",
      "\n",
      "#compose all modifiers and filters\n",
      "\n",
      "from eden.modifier.fasta import fasta_to_fasta, one_line_modifier, replace_modifier, split_regex_modifier, split_modifier, keep_modifier\n",
      "#replace Ts with Us\n",
      "iterable = fasta_to_fasta(uri, modifier=replace_modifier, regex='T', replacement='U')\n",
      "#split out sequences that are not stretches of Ns  \n",
      "iterable = fasta_to_fasta(iterable, modifier=split_regex_modifier, regex=\"([^N]+)\" )\n",
      "#filter out small sequences, i.e. smaller than lower_quantile\n",
      "iterable = fasta_to_fasta(iterable, modifier=keep_modifier, regex=\"(.{%d,})\"%min_lenght )\n",
      "#split large sequences into overlapping windows of size comparable with the Rfam average seq lenght\n",
      "iterable = fasta_to_fasta( iterable, modifier=split_modifier, window=max_lenght, step=int(max_lenght / 4) )\n",
      "#keep only the sequences that are matched by the regex\n",
      "iterable = fasta_to_fasta(iterable, modifier=keep_modifier, regex=regex )\n",
      "#add domain specific knowledge: tRNA specific Isotype / Anticodon\n",
      "regex_trna = 'AGC|GGC|CGC|UGC|ACC|GCC|CCC|UCC|AGG|GGG|CGG|UGG|AGU|GGU|CGU|UGU|AAC|GAC|CAC|UAC|AGA|GGA|CGA|UGA|ACU|GCU|ACG|GCG|CCG|UCG|CCU|UCU|AAG|GAG|CAG|UAG|CAA|UAA|AAA|GAA|AUU|GUU|CUU|UUU|AUC|GUC|CUC|UUC|AUG|GUG|CUG|UUG|AAU|GAU|UAU|CAU|AUA|GUA|CUA|UUA|ACA|GCA|CCA|UCA'\n",
      "#keep only the sequences that are matched by the regex_trna\n",
      "iterable = fasta_to_fasta(iterable, modifier=keep_modifier, regex=regex_trna )\n",
      "#filter sequences using predictive model\n",
      "iterable = out_of_core_list_filter( iterable, threshold=threshold, pre_process=pre_process, estimator=estimator, vectorizer=vectorizer )\n",
      "#extract one line\n",
      "iterable = fasta_to_fasta( iterable, modifier=one_line_modifier, one_line=True )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#run the filter on the genome and save results\n",
      "\n",
      "from datetime import datetime\n",
      "import sys\n",
      "\n",
      "results = []\n",
      "\n",
      "f = open('result','a')\n",
      "print >> f, '-'*80\n",
      "print >> f, rfam_id\n",
      "print >> f, datetime.now() \n",
      "\n",
      "#display and save results    \n",
      "for line in iterable:\n",
      "    print line\n",
      "    sys.stdout.flush()\n",
      "    print >> f, line\n",
      "    f.flush()\n",
      "    results.append(line)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}