{
 "metadata": {
  "name": "",
  "signature": "sha256:92c9e77333e5332cbb6f1e31a8b7faa0973ce790410941dff69849cea80a4b87"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#RNA family characterization\n",
      "\n",
      "Application scenario: we want to characterize RNA family A with respect to RNA family B, in other words, we are interested in identifying regions with their structural contexts that are characteristic of family A but not family B"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import pylab as pl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Vectorization setup\n",
      "\n",
      "we set the 'resolution' of the vectorization\n",
      "\n",
      "the radius parameter is metaphorically equivalent to the pixel resolution in an image \n",
      "\n",
      "the distance parameter is metaphorically equivalent to the number of shades of colors in an image"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.graph import ListVectorizer\n",
      "vec = ListVectorizer(r=2, d=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "prepare a function that composes all design actions over the original data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import *\n",
      "def compose_seq(seqs):\n",
      "    \n",
      "    #NOTE: we have to duplicate the sequences iterator if we want to use different modifiers in parallel\n",
      "    num = 3\n",
      "    seqs_list = tee(seqs,num)\n",
      "    \n",
      "    graphs_list = list()\n",
      "    weights = list()\n",
      "    \n",
      "    #1\n",
      "    #rna shapes\n",
      "    from eden.converter.rna.rnashapes import rnashapes_to_eden\n",
      "    graphs = rnashapes_to_eden(input = seqs_list[0], input_type = 'list', shape_type=5, energy_range=35, max_num=3)\n",
      "    \n",
      "    graphs_list.append(graphs)\n",
      "    weights.append(0.6)\n",
      "    \n",
      "    #2\n",
      "    #sequence    \n",
      "    from eden.converter.fasta import fasta_to_eden\n",
      "    graphs = fasta_to_eden(input = seqs_list[1], input_type = 'list')\n",
      "\n",
      "    graphs_list.append(graphs)\n",
      "    weights.append(0.10)\n",
      "    \n",
      "    #3\n",
      "    #contraction structure\n",
      "    from eden.converter.rna.rnashapes import rnashapes_to_eden\n",
      "    graphs = rnashapes_to_eden(input = seqs_list[2], input_type = 'list', shape_type=5, energy_range=35, max_num=3)\n",
      "    #annotate in node attribute 'type' the incident edges' labels\n",
      "    from eden.modifier.graph import vertex_attributes\n",
      "    graphs = vertex_attributes.incident_edge_label(graphs, level = 1, output_attribute = 'type', separator = '.')\n",
      "    from eden.modifier.graph.structure import contraction, contraction_modifier\n",
      "    label_modifier = contraction_modifier(attribute_in='type', attribute_out='label', reduction='set_categorical')\n",
      "    #reduce all 'weight' attributes of contracted nodes using a sum to be written in the 'weight' attribute of the resulting graph \n",
      "    weight_modifier = contraction_modifier(attribute_in='weight', attribute_out='weight', reduction='sum')\n",
      "    modifiers = [label_modifier, weight_modifier]\n",
      "    #contract the graph on the 'type' attribute\n",
      "    graphs = contraction(graphs, contraction_attribute = 'type', modifiers = modifiers)\n",
      "    \n",
      "    graphs_list.append(graphs)\n",
      "    weights.append(0.30)\n",
      "\n",
      "    \n",
      "    return (graphs_list, weights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compose(url_string):\n",
      "    from eden.modifier.fasta import fasta_to_fasta\n",
      "    seqs = fasta_to_fasta(input = url_string, input_type = 'url')\n",
      "    return compose_seq(seqs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compose_shuffled(url_string):\n",
      "    from eden.modifier.fasta import fasta_to_fasta, shuffle_modifier\n",
      "    seqs = fasta_to_fasta(input = url_string, input_type = 'url', modifier = shuffle_modifier, times = 1)\n",
      "    return compose_seq(seqs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rfam_url(family_id):\n",
      "    return 'http://rfam.xfam.org/family/%s/alignment?acc=%s&format=fastau&download=0'%(family_id,family_id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rfam_id = 'RF00001'\n",
      "print rfam_url(rfam_id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://rfam.xfam.org/family/RF00001/alignment?acc=RF00001&format=fastau&download=0\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Vectorization\n",
      "\n",
      "we employ the vectorizer to transform the graph instances into sparse vectors\n",
      "we collect all the vectors in a data matrix \n",
      "depending on the number of instances and the desired resolution, the procedure can take from seconds to minutes for a few hundreds of sequences"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "graphs_list, weights = compose(rfam_url(rfam_id))\n",
      "X1=vec.transform(graphs_list, weights = weights, n_jobs = 1)\n",
      "print 'Instances: %d ; Features: %d with an avg of %d features per instance' % (X1.shape[0], X1.shape[1],  X1.getnnz()/X1.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 712 ; Features: 1048577 with an avg of 1828 features per instance\n",
        "CPU times: user 3min 39s, sys: 10.7 s, total: 3min 50s\n",
        "Wall time: 9min 42s\n"
       ]
      }
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "repeat the procedure on the shuffled sequences and use the resulting structures as representatives for the negative class"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "graphs_list, weights = compose_shuffled(rfam_url(rfam_id))\n",
      "X2=vec.transform(graphs_list, weights=weights, n_jobs = 1)\n",
      "print 'Instances: %d ; Features: %d with an avg of %d features per instance' % (X2.shape[0], X2.shape[1],  X2.getnnz()/X2.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we concatenate the two data matrices into one matrix\n",
      "and we create a target vector that identifies with +1 and -1 the instances from the first or the second RNA family"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.sparse import vstack\n",
      "import numpy as np\n",
      "\n",
      "Xpos = X1\n",
      "Xneg = X2\n",
      "\n",
      "#create target array\n",
      "yp = [1]  * Xpos.shape[0]\n",
      "yn = [-1] * Xneg.shape[0]\n",
      "y = np.array(yp + yn)\n",
      "#update data matrix\n",
      "X = vstack( [Xpos,Xneg] , format = \"csr\")\n",
      "print 'Instances: %d ; Features: %d with an avg of %d features per instance' % (X.shape[0], X.shape[1],  X.getnnz()/X.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fit a predictor"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#induce a stochastic gradient descent SVM predictive model\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.grid_search import RandomizedSearchCV\n",
      "from sklearn import cross_validation\n",
      "from scipy.stats import randint\n",
      "from scipy.stats import uniform\n",
      "import numpy as np\n",
      "from scipy import stats\n",
      "\n",
      "predictor = SGDClassifier()\n",
      "#hyperparameter optimization\n",
      "param_dist = {\"n_iter\": randint(5, 100),\n",
      "              \"power_t\": uniform(0.1),\n",
      "              \"alpha\": uniform(1e-08,1e-03),\n",
      "              \"eta0\" : uniform(1e-03,10),\n",
      "              \"penalty\": [\"l1\", \"l2\", \"elasticnet\"],\n",
      "              \"learning_rate\": [\"invscaling\", \"constant\",\"optimal\"]}\n",
      "scoring = 'roc_auc'\n",
      "n_iter_search = 20\n",
      "random_search = RandomizedSearchCV(predictor,param_distributions=param_dist,n_iter=n_iter_search,cv=5,scoring=scoring,n_jobs=8)\n",
      "random_search.fit(X, y)\n",
      "optpredictor= SGDClassifier(shuffle=True, n_jobs=-1, **random_search.best_params_)\n",
      "#fit the predictor on all available data\n",
      "optpredictor.fit(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "print 'Classifier:'\n",
      "print optpredictor\n",
      "print '-'*80\n",
      "\n",
      "print 'Predictive performance:'\n",
      "#assess the generalization capacity of the model via a 10-fold cross validation\n",
      "for scoring in ['precision', 'recall', 'f1', 'average_precision', 'roc_auc']:\n",
      "    scores = cross_validation.cross_val_score(optpredictor, X, y,cv=5, scoring=scoring, n_jobs=8)\n",
      "    print('%20s: %.3f +- %.3f' % (scoring, np.mean(scores),np.std(scores)))\n",
      "print '-'*80"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}