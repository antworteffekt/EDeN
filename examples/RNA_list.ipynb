{
 "metadata": {
  "name": "",
  "signature": "sha256:9c90f0c8b6f8859317086f39679cdf7f4efcea5779de4240d4872c8bc01e1a28"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#RNA family characterization\n",
      "\n",
      "Application scenario: we want to characterize RNA family A with respect to RNA family B, in other words, we are interested in identifying regions with their structural contexts that are characteristic of family A but not family B"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import pylab as pl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Vectorization setup\n",
      "\n",
      "we set the 'resolution' of the vectorization\n",
      "\n",
      "the radius parameter is metaphorically equivalent to the pixel resolution in an image \n",
      "\n",
      "the distance parameter is metaphorically equivalent to the number of shades of colors in an image"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.graph import ListVectorizer\n",
      "vec = ListVectorizer(r=1, d=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "prepare a function that composes all design actions over the original data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import *\n",
      "def compose_seq(seqs):\n",
      "    \n",
      "    #NOTE: we have to duplicate the sequences iterator if we want to use different modifiers in parallel\n",
      "    num = 3\n",
      "    seqs_list = tee(seqs,num)\n",
      "    \n",
      "    graphs_list = list()\n",
      "    weights = list()\n",
      "    \n",
      "    #1\n",
      "    #rna shapes\n",
      "    from eden.converter.rna.rnashapes import rnashapes_to_eden\n",
      "    graphs = rnashapes_to_eden(input = seqs_list[0], input_type = 'list', shape_type=5, energy_range=35, max_num=3)\n",
      "    \n",
      "    graphs_list.append(graphs)\n",
      "    weights.append(0.6)\n",
      "    \n",
      "    #2\n",
      "    #sequence    \n",
      "    from eden.converter.fasta import fasta_to_eden\n",
      "    graphs = fasta_to_eden(input = seqs_list[1], input_type = 'list')\n",
      "\n",
      "    graphs_list.append(graphs)\n",
      "    weights.append(0.10)\n",
      "    \n",
      "    #3\n",
      "    #contraction structure\n",
      "    from eden.converter.rna.rnashapes import rnashapes_to_eden\n",
      "    graphs = rnashapes_to_eden(input = seqs_list[2], input_type = 'list', shape_type=5, energy_range=35, max_num=3)\n",
      "    #annotate in node attribute 'type' the incident edges' labels\n",
      "    from eden.modifier.graph import vertex_attributes\n",
      "    graphs = vertex_attributes.incident_edge_label(graphs, level = 1, output_attribute = 'type', separator = '.')\n",
      "    from eden.modifier.graph.structure import contraction, contraction_modifier\n",
      "    label_modifier = contraction_modifier(input='type', output='label', action='set_categorical')\n",
      "    #reduce all 'weight' attributes of contracted nodes using a sum to be written in the 'weight' attribute of the resulting graph \n",
      "    weight_modifier = contraction_modifier(input='weight', output='weight', action='sum')\n",
      "    modifiers = [label_modifier, weight_modifier]\n",
      "    #contract the graph on the 'type' attribute\n",
      "    graphs = contraction(graphs, contraction_attribute = 'type', modifiers = modifiers)\n",
      "    \n",
      "    graphs_list.append(graphs)\n",
      "    weights.append(0.30)\n",
      "\n",
      "    \n",
      "    return (graphs_list, weights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compose(url_string):\n",
      "    from eden.modifier.fasta import fasta_to_fasta\n",
      "    seqs = fasta_to_fasta(input = url_string, input_type = 'url')\n",
      "    return compose_seq(seqs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compose_shuffled(url_string):\n",
      "    from eden.modifier.fasta import fasta_to_fasta, shuffle_modifier\n",
      "    seqs = fasta_to_fasta(input = url_string, input_type = 'url', modifier = shuffle_modifier, times = 1)\n",
      "    return compose_seq(seqs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rfam_url(family_id):\n",
      "    return 'http://rfam.xfam.org/family/%s/alignment?acc=%s&format=fastau&download=0'%(family_id,family_id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rfam_id = 'RF00871'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Vectorization\n",
      "\n",
      "we employ the vectorizer to transform the graph instances into sparse vectors\n",
      "we collect all the vectors in a data matrix \n",
      "depending on the number of instances and the desired resolution, the procedure can take from seconds to minutes for a few hundreds of sequences"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "graphs_list, weights = compose(rfam_url(rfam_id))\n",
      "X1=vec.transform(graphs_list, weights = weights, n_jobs = 1)\n",
      "print 'Instances: %d ; Features: %d with an avg of %d features per instance' % (X1.shape[0], X1.shape[1],  X1.getnnz()/X1.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 13 ; Features: 1048577 with an avg of 66 features per instance\n",
        "CPU times: user 1.4 s, sys: 134 ms, total: 1.54 s\n",
        "Wall time: 11.7 s\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "repeat the procedure on a different RNA family that will be used as negative class"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "graphs_list, weights = compose_shuffled(rfam_url(rfam_id))\n",
      "X2=vec.transform(graphs_list, weights=weights, n_jobs = 1)\n",
      "print 'Instances: %d ; Features: %d with an avg of %d features per instance' % (X2.shape[0], X2.shape[1],  X2.getnnz()/X2.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 13 ; Features: 1048577 with an avg of 63 features per instance\n",
        "CPU times: user 1.39 s, sys: 94.3 ms, total: 1.48 s\n",
        "Wall time: 14.9 s\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we concatenate the two data matrices into one matrix\n",
      "and we create a target vector that identifies with +1 and -1 the instances from the first or the second RNA family"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.sparse import vstack\n",
      "import numpy as np\n",
      "\n",
      "Xpos = X1\n",
      "Xneg = X2\n",
      "\n",
      "#create target array\n",
      "yp = [1]  * Xpos.shape[0]\n",
      "yn = [-1] * Xneg.shape[0]\n",
      "y = np.array(yp + yn)\n",
      "#update data matrix\n",
      "X = vstack( [Xpos,Xneg] , format = \"csr\")\n",
      "print 'Instances: %d ; Features: %d with an avg of %d features per instance' % (X.shape[0], X.shape[1],  X.getnnz()/X.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 26 ; Features: 1048577 with an avg of 64 features per instance\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fit a predictor"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#induce a stochastic gradient descent SVM predictive model\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.grid_search import RandomizedSearchCV\n",
      "from sklearn import cross_validation\n",
      "from scipy.stats import randint\n",
      "from scipy.stats import uniform\n",
      "import numpy as np\n",
      "from scipy import stats\n",
      "\n",
      "predictor = SGDClassifier()\n",
      "#hyperparameter optimization\n",
      "param_dist = {\"n_iter\": randint(5, 100),\n",
      "              \"power_t\": uniform(0.1),\n",
      "              \"alpha\": uniform(1e-08,1e-03),\n",
      "              \"eta0\" : uniform(1e-03,10),\n",
      "              \"penalty\": [\"l1\", \"l2\", \"elasticnet\"],\n",
      "              \"learning_rate\": [\"invscaling\", \"constant\",\"optimal\"]}\n",
      "scoring = 'roc_auc'\n",
      "n_iter_search = 20\n",
      "random_search = RandomizedSearchCV(predictor,param_distributions=param_dist,n_iter=n_iter_search,cv=5,scoring=scoring,n_jobs=8)\n",
      "random_search.fit(X, y)\n",
      "optpredictor= SGDClassifier(shuffle=True, n_jobs=-1, **random_search.best_params_)\n",
      "#fit the predictor on all available data\n",
      "optpredictor.fit(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 414 ms, sys: 70.4 ms, total: 485 ms\n",
        "Wall time: 3.87 s\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "print 'Classifier:'\n",
      "print optpredictor\n",
      "print '-'*80\n",
      "\n",
      "print 'Predictive performance:'\n",
      "#assess the generalization capacity of the model via a 10-fold cross validation\n",
      "for scoring in ['precision', 'recall', 'f1', 'average_precision', 'roc_auc']:\n",
      "    scores = cross_validation.cross_val_score(optpredictor, X, y,cv=5, scoring=scoring, n_jobs=8)\n",
      "    print('%20s: %.3f +- %.3f' % (scoring, np.mean(scores),np.std(scores)))\n",
      "print '-'*80"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Classifier:\n",
        "SGDClassifier(alpha=0.000997866078885, class_weight=None, epsilon=0.1,\n",
        "       eta0=6.49822313379, fit_intercept=True, l1_ratio=0.15,\n",
        "       learning_rate='invscaling', loss='hinge', n_iter=23, n_jobs=-1,\n",
        "       penalty='l1', power_t=0.294628798774, random_state=None,\n",
        "       shuffle=True, verbose=0, warm_start=False)\n",
        "--------------------------------------------------------------------------------\n",
        "Predictive performance:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "           precision: 1.000 +- 0.000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "              recall: 0.767 +- 0.291\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                  f1: 0.833 +- 0.211\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   average_precision: 0.970 +- 0.060\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             roc_auc: 0.956 +- 0.089\n",
        "--------------------------------------------------------------------------------\n",
        "CPU times: user 213 ms, sys: 125 ms, total: 338 ms\n",
        "Wall time: 1.34 s\n"
       ]
      }
     ],
     "prompt_number": 20
    }
   ],
   "metadata": {}
  }
 ]
}