{
 "metadata": {
  "name": "",
  "signature": "sha256:ca749d84ed14c956147868e896493b8f5feebff93464d88ad22bb60ffeecef0e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%reload_ext autoreload"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import pylab as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def describe(X):\n",
      "    print 'Instances: %d ; Features: %d with an avg of %d features per instance' % (X.shape[0], X.shape[1],  X.getnnz()/X.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rfam_url(family_id):\n",
      "    return 'http://rfam.xfam.org/family/%s/alignment?acc=%s&format=fastau&download=0'%(family_id,family_id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "\n",
      "def join_pre_processes( data, pre_processes, weights):\n",
      "    if hasattr( data, '__iter__' ):\n",
      "        iterable = data\n",
      "    else: #if not then process url or file with fasta_to_fasta\n",
      "        from eden.modifier.fasta import fasta_to_fasta\n",
      "        iterable = fasta_to_fasta( data )\n",
      "        \n",
      "    graphs_list = list()\n",
      "    assert(len(weights) == len(pre_processes)),'Different lengths'\n",
      "    #NOTE: we have to duplicate the sequences iterator if we want to use different modifiers in parallel\n",
      "    iterables = itertools.tee( iterable, len(pre_processes) )\n",
      "    for pre_process_item, iterable_item in zip(pre_processes, iterables):\n",
      "        graphs_list.append( pre_process_item( iterable_item ) )\n",
      "    return (graphs_list, weights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_rnashapes( iterable ):\n",
      "    from eden.converter.rna.rnashapes import rnashapes_to_eden\n",
      "    graphs = rnashapes_to_eden( iterable, shape_type = 5, energy_range = 35, max_num = 3 )\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_fasta( iterable ):\n",
      "    from eden.converter.fasta import fasta_to_eden\n",
      "    graphs = fasta_to_eden( iterable )\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_structure( iterable ):\n",
      "    from eden.converter.rna.rnashapes_struct import rnashapes_struct_to_eden\n",
      "    graphs = rnashapes_struct_to_eden(iterable, shape=True, shape_type=5, energy_range=35, max_num=3)\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_energy( iterable ):\n",
      "    from eden.converter.rna.rnashapes_struct import rnashapes_struct_to_eden\n",
      "    graphs = rnashapes_struct_to_eden(iterable, energy=True, dotbracket=False, shape_type=5, energy_range=35, max_num=3)\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_contraction( iterable ):\n",
      "    from eden.converter.rna.rnashapes import rnashapes_to_eden\n",
      "    graphs = rnashapes_to_eden( iterable, shape_type=5, energy_range=35, max_num=3 )\n",
      "    \n",
      "    #annotate in node attribute 'type' the incident edges' labels\n",
      "    from eden.modifier.graph import vertex_attributes\n",
      "    graphs = vertex_attributes.incident_edge_label(graphs, level=1, output_attribute='type', separator='.')\n",
      "    \n",
      "    from eden.modifier.graph.structure import contraction, contraction_modifier\n",
      "    label_modifier = contraction_modifier(attribute_in='type', attribute_out='label', reduction='set_categorical')\n",
      "    \n",
      "    #reduce all 'weight' attributes of contracted nodes using a sum to be written in the 'weight' attribute of the resulting graph \n",
      "    weight_modifier = contraction_modifier(attribute_in='weight', attribute_out='weight', reduction='sum')\n",
      "    modifiers = [label_modifier, weight_modifier]\n",
      "    \n",
      "    #contract the graph on the 'type' attribute\n",
      "    graphs = contraction(graphs, contraction_attribute='type', modifiers=modifiers)\n",
      "    \n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process( data ):\n",
      "    pre_processes = [pre_process_energy, pre_process_rnashapes, pre_process_fasta, pre_process_structure, pre_process_contraction]\n",
      "    weights = [0.4, 0.2, 0.05, 0.3, 0.05]\n",
      "    return join_pre_processes( data, pre_processes, weights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rfam_id = 'RF00871' #microRNA mir-689\n",
      "rfam_id = 'RF00005' #tRNA"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def model(rfam_id, pre_process):\n",
      "\n",
      "    from eden.graph import Vectorizer\n",
      "    vectorizer = Vectorizer( r=2, d=2 )\n",
      "    n_jobs = 1\n",
      "\n",
      "    graphs = pre_process( rfam_url( rfam_id ) )\n",
      "    X1 = vectorizer.transform( graphs, n_jobs=n_jobs )\n",
      "    describe(X1)\n",
      "    \n",
      "    from eden.modifier.fasta import fasta_to_fasta, shuffle_modifier\n",
      "    graphs = pre_process( fasta_to_fasta( rfam_url( rfam_id ) , modifier=shuffle_modifier, times=2, order=2) )\n",
      "    X2 = vectorizer.transform( graphs, n_jobs=n_jobs )\n",
      "    describe(X2)\n",
      "    \n",
      "    from eden.util import fit_estimator\n",
      "    estimator = fit_estimator( positive_data_matrix=X1, negative_data_matrix=X2, cv=5 )\n",
      "    \n",
      "    return estimator, vectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def list_model(rfam_id, pre_process):\n",
      "\n",
      "    from eden.graph import ListVectorizer\n",
      "    vectorizer = ListVectorizer( r=2, d=2 )\n",
      "    n_jobs = -1\n",
      "\n",
      "    graphs_list, weights = pre_process( rfam_url( rfam_id ) )\n",
      "    X1 = vectorizer.transform( graphs_list, weights=weights, n_jobs=n_jobs )\n",
      "    describe(X1)\n",
      "    \n",
      "    from eden.modifier.fasta import fasta_to_fasta, shuffle_modifier\n",
      "    graphs_list, weights = pre_process( fasta_to_fasta( rfam_url( rfam_id ) , modifier=shuffle_modifier, times=2, order=2) )\n",
      "    X2 = vectorizer.transform( graphs_list, weights=weights, n_jobs=n_jobs )\n",
      "    describe(X2)\n",
      "    \n",
      "    from eden.util import fit_estimator\n",
      "    estimator = fit_estimator( positive_data_matrix=X1, negative_data_matrix=X2, cv=5 )\n",
      "    \n",
      "    return estimator, vectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "estimator, vectorizer = model(rfam_id, pre_process_rnashapes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 954 ; Features: 1048577 with an avg of 906 features per instance\n",
        "Instances: 1908 ; Features: 1048577 with an avg of 883 features per instance"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Classifier:\n",
        "SGDClassifier(alpha=4.43815160588e-06, class_weight='auto', epsilon=0.1,\n",
        "       eta0=6.21327456457, fit_intercept=True, l1_ratio=0.15,\n",
        "       learning_rate='optimal', loss='hinge', n_iter=86, n_jobs=-1,\n",
        "       penalty='l2', power_t=1.07665190495, random_state=None,\n",
        "       shuffle=True, verbose=0, warm_start=False)\n",
        "-------------------------------------------------------------------------\n",
        "Predictive performance:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "            accuracy: 0.971 +- 0.013\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "           precision: 0.970 +- 0.022\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "              recall: 0.941 +- 0.020\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                  f1: 0.955 +- 0.019\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   average_precision: 0.992 +- 0.005\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             roc_auc: 0.995 +- 0.003\n",
        "-------------------------------------------------------------------------\n",
        "CPU times: user 5min 2s, sys: 33.1 s, total: 5min 35s\n",
        "Wall time: 8min 22s\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "estimator_str, vectorizer_str = list_model(rfam_id, pre_process)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 954 ; Features: 1048577 with an avg of 1566 features per instance\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 1908 ; Features: 1048577 with an avg of 1501 features per instance\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Classifier:\n",
        "SGDClassifier(alpha=1.25104713593e-05, class_weight='auto', epsilon=0.1,\n",
        "       eta0=1.91559591178, fit_intercept=True, l1_ratio=0.15,\n",
        "       learning_rate='constant', loss='hinge', n_iter=79, n_jobs=-1,\n",
        "       penalty='l2', power_t=0.241293338315, random_state=None,\n",
        "       shuffle=True, verbose=0, warm_start=False)\n",
        "-------------------------------------------------------------------------\n",
        "Predictive performance:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "            accuracy: 0.988 +- 0.004\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "           precision: 0.989 +- 0.003\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "              recall: 0.975 +- 0.012\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                  f1: 0.982 +- 0.007\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   average_precision: 0.997 +- 0.001\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             roc_auc: 0.998 +- 0.001\n",
        "-------------------------------------------------------------------------\n",
        "CPU times: user 5min 32s, sys: 1min 48s, total: 7min 20s\n",
        "Wall time: 13min 47s\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#use compute_max_subarrays to return an iterator over motives \n",
      "from eden.util.iterated_maximum_subarray import compute_max_subarrays\n",
      "\n",
      "def motives(iterable, min_subarray_size = None, max_subarray_size = None):\n",
      "    for graph in iterable:\n",
      "        subarrays = compute_max_subarrays(graph=graph, min_subarray_size=min_subarray_size, max_subarray_size=max_subarray_size)\n",
      "        if subarrays:\n",
      "            for subarray in subarrays:\n",
      "                yield ''.join(subarray['subarray'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.graph import Annotator\n",
      "annotator = Annotator( estimator = estimator, vectorizer = vectorizer )\n",
      "\n",
      "#annotate graphs with node importance \n",
      "graphs = pre_process_rnashapes( rfam_url( rfam_id ) )\n",
      "graphs = annotator.transform( graphs )\n",
      "\n",
      "#use node importance and 'position' attribute to identify max_subarrays of a specific size\n",
      "iterable = motives(graphs, min_subarray_size=5, max_subarray_size=18)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#collect all motives and return the unique occurrences\n",
      "motif_list = set(iterable)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 1min 41s, sys: 6.11 s, total: 1min 47s\n",
        "Wall time: 2min 12s\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#count occurrences of motives in original dataset to determine support of each motif\n",
      "from collections import defaultdict\n",
      "\n",
      "from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "iterable = fasta_to_fasta(rfam_url( rfam_id ), modifier=one_line_modifier, sequence_only=True)\n",
      "\n",
      "motif_counter = defaultdict(int)\n",
      "for seq in iterable:\n",
      "    for motif in motif_list:\n",
      "        if seq.find(motif) != -1:\n",
      "            motif_counter[motif] += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#select only motives with support higher than a user defined threshold\n",
      "motif_support_threshold = 50\n",
      "selcted_motifs = [motif for motif in motif_counter if motif_counter[motif] >= motif_support_threshold]    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plot histogram of lengths\n",
      "print 'Num: %d motives selected'%len(selcted_motifs)\n",
      "lens = [len(motif) for motif in selcted_motifs]\n",
      "plt.hist(lens, 10, histtype='stepfilled', facecolor='r', alpha=0.6)\n",
      "plt.grid()\n",
      "plt.title('Motives lenght distribution')\n",
      "plt.xlabel('size')\n",
      "plt.ylabel('frequency')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Num: 25 motives selected\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEZCAYAAACZwO5kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERERERERERGR/dx/AbM/W+vy1fSIAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x109b7ff90>"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#build a regex expression that matches the occurrence of at least one of the motives\n",
      "regex=''\n",
      "for m in sorted(selcted_motifs): regex += '|' + m\n",
      "regex = regex[1:]\n",
      "print regex"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "AAAGCA|AAAUCCU|AAGGCA|AGGUUCAA|AGGUUCGAAUCCU|AGUUCGA|CAGGUUC|GGUUCAA|GGUUCAAAU|GGUUCGA|GGUUCGAAU|GGUUCGAAUCC|GGUUCGAAUCCC|GGUUCGAAUCCU|GGUUCGAU|GUUCAAAU|GUUCAAAUCC|GUUCGAAU|GUUCGAU|UAGCUUAA|UGGUAGAGC|UGGUUAA|UUCAAAU|UUCAAAUC|UUCGAAU\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#compute statistics when using the motives as indicators for the target family on the original data \n",
      "#and on a randomly permuted dataset\n",
      "\n",
      "from eden.modifier.fasta import fasta_to_fasta, keep_modifier, shuffle_modifier\n",
      "\n",
      "def motives_discriminative_performance_evaluation(data, regex):\n",
      "    iterable = fasta_to_fasta( data , modifier=keep_modifier, regex=regex )\n",
      "    true_positive_count = sum(1 for x in iterable)\n",
      "    iterable = fasta_to_fasta( data )\n",
      "    positive_count = sum(1 for x in iterable)\n",
      "    iterable = fasta_to_fasta( data , modifier=shuffle_modifier, times=20, order=2)\n",
      "    it1,it2 = itertools.tee(iterable)\n",
      "    negative_count = sum(1 for x in it1)\n",
      "    iterable = fasta_to_fasta( it2 , modifier=keep_modifier, regex=regex )\n",
      "    false_positive_count = sum(1 for x in iterable)\n",
      "    false_negative_count =  positive_count - true_positive_count\n",
      "    true_negative_count = negative_count - false_negative_count\n",
      "\n",
      "    recall = true_positive_count/float(true_positive_count + false_negative_count)\n",
      "    precision = true_positive_count/float(true_positive_count + false_positive_count)\n",
      "    f1 = 2 * precision * recall / (precision + recall)\n",
      "\n",
      "    print 'pos:%d neg:%d TP:%d FP:%d TN:%d FN:%d' % (positive_count, negative_count, true_positive_count, false_positive_count, true_negative_count, false_negative_count)\n",
      "    print 'precision:%0.3f recall:%0.3f f1:%0.3f' % (precision, recall, f1)\n",
      "    print 'dataset reduction: from %d to %d = %0.3f' % (negative_count, false_positive_count, false_positive_count/float(negative_count))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "motives_discriminative_performance_evaluation(rfam_url( rfam_id ), regex)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "pos:1908 neg:38160 TP:1470 FP:2888 TN:37722 FN:438\n",
        "precision:0.337 recall:0.770 f1:0.469\n",
        "dataset reduction: from 38160 to 2888 = 0.076\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#extract statistics on the average lenght of the sequences in the given Rfam family\n",
      "#use this information to determine the size of the window when scanning the genome\n",
      "import numpy\n",
      "from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "\n",
      "low = 25\n",
      "high = 75\n",
      "\n",
      "iterable = fasta_to_fasta( rfam_url( rfam_id ), modifier=one_line_modifier, sequence_only=True)\n",
      "len_seqs = [len(seq) for seq in iterable]\n",
      "lower_quantile = int(numpy.percentile(len_seqs, low))\n",
      "upper_quantile = int(numpy.percentile(len_seqs, high))\n",
      "\n",
      "num_seqs = len(len_seqs)\n",
      "\n",
      "print 'Rfam family %s has %d sequences' % (rfam_id, num_seqs)\n",
      "print 'more than %d%% of the sequences have lenght smaller than: %d ' % (high, upper_quantile)\n",
      "print 'less then %d%% of the sequences have lenght smaller than: %d ' % (low, lower_quantile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Rfam family RF00005 has 954 sequences\n",
        "more than 75% of the sequences have lenght smaller than: 74 \n",
        "less then 25% of the sequences have lenght smaller than: 71 \n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#compose all pre processing operations on the genome\n",
      "from eden.modifier.fasta import fasta_to_fasta, replace_modifier, split_regex_modifier, split_modifier, keep_modifier\n",
      "\n",
      "def genome_fasta_pre_processing(uri, min_lenght=None, max_lenght=None ):\n",
      "    #replace Ts with Us\n",
      "    iterable = fasta_to_fasta(uri, modifier=replace_modifier, regex='T', replacement='U')\n",
      "    #split out sequences that are not stretches of Ns  \n",
      "    iterable = fasta_to_fasta(iterable, modifier=split_regex_modifier, regex=\"([^N]+)\" )\n",
      "    #filter out small sequences, i.e. smaller than lower_quantile\n",
      "    iterable = fasta_to_fasta(iterable, modifier=keep_modifier, regex=\"(.{%d,})\"%min_lenght )\n",
      "    #split large sequences into overlapping windows of size comparable with the Rfam average seq lenght\n",
      "    iterable = fasta_to_fasta( iterable, modifier=split_modifier, window=max_lenght, step=int(max_lenght / 4) )\n",
      "    return iterable"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#add domain specific knowledge: tRNA specific Isotype / Anticodon\n",
      "regex_trna = 'AGC|GGC|CGC|TGC|ACC|GCC|CCC|TCC|AGG|GGG|CGG|TGG|AGT'\n",
      "regex_trna += '|GGT|CGT|TGT|AAC|GAC|CAC|TAC|AGA|GGA|CGA|TGA|ACT|GCT'\n",
      "regex_trna += '|ACG|GCG|CCG|TCG|CCT|TCT|AAG|GAG|CAG|TAG|CAA|TAA|AAA'\n",
      "regex_trna += '|GAA|ATT|GTT|CTT|TTT|ATC|GTC|CTC|TTC|ATG|GTG|CTG|TTG'\n",
      "regex_trna += '|AAT|GAT|TAT|CAT|ATA|GTA|CTA|TTA|ACA|GCA|CCA|TCA'  \n",
      "regex_trna = regex_trna.replace('T','U')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#pre process the genome in windows\n",
      "iterable = genome_fasta_pre_processing('dm6.fa.masked', min_lenght=lower_quantile, max_lenght=upper_quantile)\n",
      "#keep only the sequences that are matched by the regex\n",
      "iterable = fasta_to_fasta(iterable, modifier=keep_modifier, regex=regex )\n",
      "#keep only the sequences that are matched by the regex_trna\n",
      "iterable = fasta_to_fasta(iterable, modifier=keep_modifier, regex=regex_trna )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#define a filter that uses the predictive model\n",
      "import itertools\n",
      "\n",
      "def out_of_core_list_predictions( iterable, estimator=None, vectorizer=None, pre_process=None, threshold=1 ):\n",
      "    iterable_headers, iterable_seqs = itertools.tee( iterable )\n",
      "    \n",
      "    from eden.graph import OutOfCoreListPredictor\n",
      "    out_of_core_list_predictor = OutOfCoreListPredictor( estimator=estimator, vectorizer=vectorizer )\n",
      "\n",
      "    #extract oneline fasta\n",
      "    from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "    headers = fasta_to_fasta( iterable_headers, modifier=one_line_modifier, one_line=True, one_line_separator=' ' )\n",
      "\n",
      "    #extract graphs\n",
      "    graphs_list, weights = pre_process( iterable_seqs )\n",
      "    predictions = out_of_core_list_predictor.predict(graphs_list, weights=weights)\n",
      "\n",
      "    for header, prediction in itertools.izip(headers, predictions):\n",
      "        if prediction >= threshold:\n",
      "            yield header, prediction"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#run the filter on the genome\n",
      "\n",
      "from datetime import datetime\n",
      "def parse_header(header):\n",
      "    '''process header to extract chromosome, start and end position'''\n",
      "    items = header[1:].split()\n",
      "    chromosome = items[0]\n",
      "    start = int(items[2])+int(items[4])\n",
      "    end = start + int(items[6])\n",
      "    seq = items[9]\n",
      "    id = '%s %d %d %s'%(chromosome,start,end,seq)\n",
      "    return id\n",
      "\n",
      "import sys\n",
      "f = open('result','a')\n",
      "print >> f, '-'*80\n",
      "print >> f, rfam_id\n",
      "print >> f, datetime.now() \n",
      "results = []\n",
      "for header, prediction in out_of_core_list_predictions( iterable,\n",
      "                                                       estimator=estimator_str, \n",
      "                                                       vectorizer=vectorizer_str, \n",
      "                                                       pre_process=pre_process, \n",
      "                                                       threshold=1 ):\n",
      "    id = parse_header( header )\n",
      "    #save and display results\n",
      "    results.append([id, prediction])\n",
      "    result_text = 'score: %0.1f %s' % (prediction,id)\n",
      "    print result_text\n",
      "    sys.stdout.flush()\n",
      "    print >> f, result_text\n",
      "    f.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}