{
 "metadata": {
  "name": "",
  "signature": "sha256:a20e8eba81e02e4a4db5ac5617ba3f9b55495c7b90364aaaefef5fdda3c36914"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%reload_ext autoreload"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import pylab as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING: pylab import has clobbered these variables: ['plt']\n",
        "`%matplotlib` prevents importing * from pylab and numpy\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def describe(X):\n",
      "    print 'Instances: %d ; Features: %d with an avg of %d features per instance' % (X.shape[0], X.shape[1],  X.getnnz()/X.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rfam_url(family_id):\n",
      "    return 'http://rfam.xfam.org/family/%s/alignment?acc=%s&format=fastau&download=0'%(family_id,family_id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "\n",
      "def join_pre_processes( data, pre_processes, weights):\n",
      "    if hasattr( data, '__iter__' ):\n",
      "        iterable = data\n",
      "    else: #if not then process url or file with fasta_to_fasta\n",
      "        from eden.modifier.fasta import fasta_to_fasta\n",
      "        iterable = fasta_to_fasta( data )\n",
      "        \n",
      "    graphs_list = list()\n",
      "    assert(len(weights) == len(pre_processes)),'Different lengths'\n",
      "    #NOTE: we have to duplicate the sequences iterator if we want to use different modifiers in parallel\n",
      "    iterables = itertools.tee( iterable, len(pre_processes) )\n",
      "    for pre_process_item, iterable_item in zip(pre_processes, iterables):\n",
      "        graphs_list.append( pre_process_item( iterable_item ) )\n",
      "    return (graphs_list, weights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_rnashapes( iterable ):\n",
      "    from eden.converter.rna.rnashapes import rnashapes_to_eden\n",
      "    graphs = rnashapes_to_eden( iterable, shape_type = 5, energy_range = 35, max_num = 3 )\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_fasta( iterable ):\n",
      "    from eden.converter.fasta import fasta_to_eden\n",
      "    graphs = fasta_to_eden( iterable )\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_structure( iterable ):\n",
      "    from eden.converter.rna.rnashapes_struct import rnashapes_struct_to_eden\n",
      "    graphs = rnashapes_struct_to_eden(iterable, energy=True, shape=True, shape_type=5, energy_range=35, max_num=3)\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_contraction( iterable ):\n",
      "    from eden.converter.rna.rnashapes import rnashapes_to_eden\n",
      "    graphs = rnashapes_to_eden( iterable, shape_type=5, energy_range=35, max_num=3 )\n",
      "    \n",
      "    #annotate in node attribute 'type' the incident edges' labels\n",
      "    from eden.modifier.graph import vertex_attributes\n",
      "    graphs = vertex_attributes.incident_edge_label(graphs, level=1, output_attribute='type', separator='.')\n",
      "    \n",
      "    from eden.modifier.graph.structure import contraction, contraction_modifier\n",
      "    label_modifier = contraction_modifier(attribute_in='type', attribute_out='label', reduction='set_categorical')\n",
      "    \n",
      "    #reduce all 'weight' attributes of contracted nodes using a sum to be written in the 'weight' attribute of the resulting graph \n",
      "    weight_modifier = contraction_modifier(attribute_in='weight', attribute_out='weight', reduction='sum')\n",
      "    modifiers = [label_modifier, weight_modifier]\n",
      "    \n",
      "    #contract the graph on the 'type' attribute\n",
      "    graphs = contraction(graphs, contraction_attribute='type', modifiers=modifiers)\n",
      "    \n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process( data ):\n",
      "    weights = [0.5, 0.1, 0.1, 0.3]\n",
      "    pre_processes = [pre_process_rnashapes, pre_process_fasta, pre_process_structure, pre_process_contraction]\n",
      "    return join_pre_processes( data, pre_processes, weights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rfam_id = 'RF00005'\n",
      "rfam_id = 'RF00871'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def model(rfam_id, pre_process):\n",
      "\n",
      "    from eden.graph import Vectorizer\n",
      "    vectorizer = Vectorizer( r=2, d=2 )\n",
      "    n_jobs = 1\n",
      "\n",
      "    graphs = pre_process( rfam_url( rfam_id ) )\n",
      "    X1 = vectorizer.transform( graphs, n_jobs=n_jobs )\n",
      "    describe(X1)\n",
      "    \n",
      "    from eden.modifier.fasta import fasta_to_fasta, shuffle_modifier\n",
      "    graphs = pre_process( fasta_to_fasta( rfam_url( rfam_id ) , modifier=shuffle_modifier, times=2, order=2) )\n",
      "    X2 = vectorizer.transform( graphs, n_jobs=n_jobs )\n",
      "    describe(X2)\n",
      "    \n",
      "    from eden.util import fit_estimator\n",
      "    estimator = fit_estimator( positive_data_matrix=X1, negative_data_matrix=X2, cv=5 )\n",
      "    \n",
      "    return estimator, vectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def list_model(rfam_id, pre_process):\n",
      "\n",
      "    from eden.graph import ListVectorizer\n",
      "    vectorizer = ListVectorizer( r=2, d=2 )\n",
      "    n_jobs = 1\n",
      "\n",
      "    graphs_list, weights = pre_process( rfam_url( rfam_id ) )\n",
      "    X1 = vectorizer.transform( graphs_list, weights=weights, n_jobs=n_jobs )\n",
      "    describe(X1)\n",
      "    \n",
      "    from eden.modifier.fasta import fasta_to_fasta, shuffle_modifier\n",
      "    graphs_list, weights = pre_process( fasta_to_fasta( rfam_url( rfam_id ) , modifier=shuffle_modifier, times=2, order=2) )\n",
      "    X2 = vectorizer.transform( graphs_list, weights=weights, n_jobs=n_jobs )\n",
      "    describe(X2)\n",
      "    \n",
      "    from eden.util import fit_estimator\n",
      "    estimator = fit_estimator( positive_data_matrix=X1, negative_data_matrix=X2, cv=5 )\n",
      "    \n",
      "    return estimator, vectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "estimator_str, vectorizer_str = list_model(rfam_id, pre_process)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "estimator, vectorizer = model(rfam_id, pre_process_rnashapes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#use the compute_max_subarrays to return an iterable fasta containing the individual motives \n",
      "from eden.util.iterated_maximum_subarray import compute_max_subarrays\n",
      "\n",
      "def motives(iterable, min_subarray_size = None, max_subarray_size = None):\n",
      "    for graph in iterable:\n",
      "        subarrays = compute_max_subarrays(graph=graph, min_subarray_size=min_subarray_size, max_subarray_size=max_subarray_size)\n",
      "        if subarrays:\n",
      "            for subarray in subarrays:\n",
      "                yield ''.join(subarray['subarray'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.graph import Annotator\n",
      "annotator = Annotator( estimator = estimator, vectorizer = vectorizer )\n",
      "\n",
      "graphs = pre_process_rnashapes( rfam_url( rfam_id ) )\n",
      "graphs = annotator.transform( graphs )\n",
      "\n",
      "iterable = motives(graphs, min_subarray_size=5, max_subarray_size=18)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#collect all motives and return the unique occurrences\n",
      "motif_list = set(iterable)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 4 s, sys: 256 ms, total: 4.25 s\n",
        "Wall time: 14.5 s\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#count occurrences of motives in original dataset\n",
      "from collections import defaultdict\n",
      "\n",
      "from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "iterable = fasta_to_fasta(rfam_url( rfam_id ), modifier=one_line_modifier, sequence_only=True)\n",
      "\n",
      "motif_counter = defaultdict(int)\n",
      "for seq in iterable:\n",
      "    for motif in motif_list:\n",
      "        if seq.find(motif) != -1:\n",
      "            motif_counter[motif] += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "motif_support_threshold = 2\n",
      "selcted_motifs = [motif for motif in motif_counter if motif_counter[motif] >= motif_support_threshold]    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Num: %d motives selected'%len(selcted_motifs)\n",
      "lens = [len(motif) for motif in selcted_motifs]\n",
      "#plot histogram of lengths\n",
      "plt.hist(lens, 10, histtype='stepfilled', facecolor='r', alpha=0.6)\n",
      "plt.grid()\n",
      "plt.title('Motives lenght distribution')\n",
      "plt.xlabel('size')\n",
      "plt.ylabel('frequency')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Num: 6 motives selected\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEZCAYAAACXRVJOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERERERERERFpkf8PRS3jq0S16AAAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x111db2fd0>"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "regex=''\n",
      "for m in sorted(selcted_motifs): regex += '|' + m\n",
      "regex = regex[1:]\n",
      "print regex"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CGCGCGUCGGGACC|CGCGUCGGGACC|CGUCGGGACC|GGUCCCCCGCCUGUCCCC|GUCCCCGUCCGUCCCC|GUCGGGACC\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.modifier.fasta import fasta_to_fasta, keep_modifier, shuffle_modifier\n",
      "\n",
      "def motives_discriminative_performance_evaluation(data, regex):\n",
      "    iterable = fasta_to_fasta( data , modifier=keep_modifier, regex=regex )\n",
      "    true_positive_count = sum(1 for x in iterable)\n",
      "    iterable = fasta_to_fasta( data )\n",
      "    positive_count = sum(1 for x in iterable)\n",
      "    iterable = fasta_to_fasta( data , modifier=shuffle_modifier, times=20, order=2)\n",
      "    it1,it2 = itertools.tee(iterable)\n",
      "    negative_count = sum(1 for x in it1)\n",
      "    iterable = fasta_to_fasta( it2 , modifier=keep_modifier, regex=regex )\n",
      "    false_positive_count = sum(1 for x in iterable)\n",
      "    false_negative_count =  positive_count - true_positive_count\n",
      "    true_negative_count = negative_count - false_negative_count\n",
      "\n",
      "    recall = true_positive_count/float(true_positive_count + false_negative_count)\n",
      "    precision = true_positive_count/float(true_positive_count + false_positive_count)\n",
      "    f1 = 2 * precision * recall / (precision + recall)\n",
      "\n",
      "    print 'pos:%d neg:%d TP:%d FP:%d TN:%d FN:%d' % (positive_count, negative_count, true_positive_count, false_positive_count, true_negative_count, false_negative_count)\n",
      "    print 'precision:%0.3f recall:%0.3f f1:%0.3f' % (precision, recall, f1)\n",
      "    print 'dataset reduction: from %d to %d = %0.3f' % (negative_count, false_positive_count, false_positive_count/float(negative_count))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "motives_discriminative_performance_evaluation(rfam_url( rfam_id ), regex)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "pos:26 neg:520 TP:26 FP:0 TN:520 FN:0\n",
        "precision:1.000 recall:1.000 f1:1.000\n",
        "dataset reduction: from 520 to 0 = 0.000\n"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#extract statistics on the average lenght of the sequences in the given Rfam family\n",
      "import numpy\n",
      "from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "\n",
      "low = 25\n",
      "high = 75\n",
      "\n",
      "iterable = fasta_to_fasta( rfam_url( rfam_id ), modifier=one_line_modifier, sequence_only=True)\n",
      "len_seqs = [len(seq) for seq in iterable]\n",
      "lower_quantile = int(numpy.percentile(len_seqs, low))\n",
      "upper_quantile = int(numpy.percentile(len_seqs, high))\n",
      "\n",
      "num_seqs = len(len_seqs)\n",
      "\n",
      "print 'Rfam family %s has %d sequences' % (rfam_id, num_seqs)\n",
      "print 'more than %d%% of the sequences have lenght smaller than: %d ' % (high, upper_quantile)\n",
      "print 'less then %d%% of the sequences have lenght smaller than: %d ' % (low, lower_quantile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Rfam family RF00871 has 13 sequences\n",
        "more than 75% of the sequences have lenght smaller than: 111 \n",
        "less then 25% of the sequences have lenght smaller than: 102 \n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.modifier.fasta import fasta_to_fasta, replace_modifier, split_regex_modifier, split_modifier, keep_modifier\n",
      "\n",
      "def genome_fasta_pre_processing(uri, min_lenght=None, max_lenght=None ):\n",
      "    #replace Ts with Us\n",
      "    iterable = fasta_to_fasta(uri, modifier=replace_modifier, regex='T', replacement='U')\n",
      "    #split out sequences that are not stretches of Ns  \n",
      "    iterable = fasta_to_fasta(iterable, modifier=split_regex_modifier, regex=\"([^N]+)\" )\n",
      "    #filter out small sequences, i.e. smaller than lower_quantile\n",
      "    iterable = fasta_to_fasta(iterable, modifier=keep_modifier, regex=\"(.{%d,})\"%min_lenght )\n",
      "    #split large sequences into overlapping windows of size comparable with the Rfam average seq lenght\n",
      "    iterable = fasta_to_fasta( iterable, modifier=split_modifier, window=max_lenght, step=int(max_lenght / 3) )\n",
      "    return iterable"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iterable = genome_fasta_pre_processing('dm6.fa.masked', min_lenght=lower_quantile, max_lenght=upper_quantile)\n",
      "iterable = fasta_to_fasta(iterable, modifier=keep_modifier, regex=regex )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "\n",
      "def out_of_core_list_predictions( iterable, estimator=None, vectorizer=None, pre_process=None, threshold=1 ):\n",
      "    iterable_headers, iterable_seqs = itertools.tee( iterable )\n",
      "    \n",
      "    from eden.graph import OutOfCoreListPredictor\n",
      "    out_of_core_list_predictor = OutOfCoreListPredictor( estimator=estimator, vectorizer=vectorizer )\n",
      "\n",
      "    #extract oneline fasta\n",
      "    from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "    headers = fasta_to_fasta( iterable_headers, modifier=one_line_modifier, one_line=True, one_line_separator=' ' )\n",
      "\n",
      "    #extract graphs\n",
      "    graphs_list, weights = pre_process( iterable_seqs )\n",
      "    predictions = out_of_core_list_predictor.predict(graphs, weights=weights)\n",
      "\n",
      "    for header, prediction in itertools.izip(headers, predictions):\n",
      "        if prediction >= threshold:\n",
      "            yield header, prediction"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "from datetime import datetime\n",
      "def parse_header(header):\n",
      "    '''process header to extract chromosome, start and end position'''\n",
      "    items = header[1:].split()\n",
      "    chromosome = items[0]\n",
      "    start = int(items[2])+int(items[4])\n",
      "    end = start + int(items[6])\n",
      "    seq = items[9]\n",
      "    id = '%s %d %d %s'%(chromosome,start,end,seq)\n",
      "    return id\n",
      "\n",
      "import sys\n",
      "f = open('result','a')\n",
      "print >> f, '-'*80\n",
      "print >> f, rfam_id\n",
      "print >> f, datetime.now() \n",
      "results = []\n",
      "for header, prediction in out_of_core_list_predictions( iterable,\n",
      "                                                       estimator=estimator_str, \n",
      "                                                       vectorizer=vectorizer_str, \n",
      "                                                       pre_process=pre_process, \n",
      "                                                       threshold=2 ):\n",
      "    id = parse_header( header )\n",
      "    #save and display results\n",
      "    results.append([id, prediction])\n",
      "    result_text = 'score: %0.1f %s' % (prediction,id)\n",
      "    print result_text\n",
      "    sys.stdout.flush()\n",
      "    print >> f, result_text\n",
      "    f.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "object of type 'generator' has no len()",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-83-6a50ecb5f28f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu\"from datetime import datetime\\ndef parse_header(header):\\n    '''process header to extract chromosome, start and end position'''\\n    items = header[1:].split()\\n    chromosome = items[0]\\n    start = int(items[2])+int(items[4])\\n    end = start + int(items[6])\\n    seq = items[9]\\n    id = '%s %d %d %s'%(chromosome,start,end,seq)\\n    return id\\n\\nimport sys\\nf = open('result','a')\\nprint >> f, '-'*80\\nprint >> f, rfam_id\\nprint >> f, datetime.now() \\nresults = []\\nfor header, prediction in out_of_core_list_predictions( iterable,\\n                                                       estimator=estimator_str, \\n                                                       vectorizer=vectorizer_str, \\n                                                       pre_process=pre_process, \\n                                                       threshold=2 ):\\n    id = parse_header( header )\\n    #save and display results\\n    results.append([id, prediction])\\n    result_text = 'score: %0.1f %s' % (prediction,id)\\n    print result_text\\n    sys.stdout.flush()\\n    print >> f, result_text\\n    f.flush()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/Library/Python/2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2160\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2162\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2163\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;32m<ipython-input-82-cc25e59abd50>\u001b[0m in \u001b[0;36mout_of_core_list_predictions\u001b[0;34m(iterable, estimator, vectorizer, pre_process, threshold)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_of_core_list_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mizip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/costa/Desktop/BTSync/Projects/EDeN/EDeN/eden/graph.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, G_iterators_list, weights)\u001b[0m\n\u001b[1;32m   1155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_iterators_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m         assert(len(G_iterators_list) == len(weights)\n\u001b[0m\u001b[1;32m   1158\u001b[0m                ), 'ERROR: weights count is different than iterators count.'\n\u001b[1;32m   1159\u001b[0m         assert(len(filter(lambda x: x < 0, weights)) ==\n",
        "\u001b[0;31mTypeError\u001b[0m: object of type 'generator' has no len()"
       ]
      }
     ],
     "prompt_number": 83
    }
   ],
   "metadata": {}
  }
 ]
}