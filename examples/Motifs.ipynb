{
 "metadata": {
  "name": "",
  "signature": "sha256:4eadcf129fe437b2af84c0153d7533dc4f170db0a40369c3556a1cc3d9d3a3d5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import pylab as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING: pylab import has clobbered these variables: ['iterable']\n",
        "`%matplotlib` prevents importing * from pylab and numpy\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%reload_ext autoreload"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "\n",
      "def out_of_core_predictions( iterable, estimator=None, vectorizer=None, pre_process=None, threshold=1 ):\n",
      "    iterable_headers, iterable_seqs = itertools.tee( iterable )\n",
      "    \n",
      "    from eden.graph import OutOfCorePredictor\n",
      "    out_of_core_predictor = OutOfCorePredictor( estimator=estimator, vectorizer=vectorizer )\n",
      "\n",
      "    #extract oneline fasta\n",
      "    from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "    headers = fasta_to_fasta( iterable_headers, modifier=one_line_modifier, one_line=True, one_line_separator=' ' )\n",
      "\n",
      "    #extract graphs\n",
      "    graphs = pre_process( iterable_seqs )\n",
      "    predictions = out_of_core_predictor.predict(graphs)\n",
      "\n",
      "    for header, prediction in itertools.izip(headers, predictions):\n",
      "        if prediction >= threshold:\n",
      "            yield header, prediction"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def describe(X):\n",
      "    print 'Instances: %d ; Features: %d with an avg of %d features per instance' % (X.shape[0], X.shape[1],  X.getnnz()/X.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rfam_url(family_id):\n",
      "    return 'http://rfam.xfam.org/family/%s/alignment?acc=%s&format=fastau&download=0'%(family_id,family_id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_rnashapes_struct( data ):\n",
      "    from eden.converter.rna.rnashapes_struct import rnashapes_struct_to_eden\n",
      "    graphs = rnashapes_struct_to_eden(data, energy=True, shape=True, shape_type=5, energy_range=35, max_num=3)\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_rnashapes( data ):\n",
      "    from eden.converter.rna.rnashapes import rnashapes_to_eden\n",
      "    graphs = rnashapes_to_eden( data, shape_type = 5, energy_range = 35, max_num = 4 )\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rfam_id = 'RF00871'\n",
      "rfam_id = 'RF00005'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def model(rfam_id, pre_process):\n",
      "    \n",
      "    from eden.graph import Vectorizer\n",
      "    vectorizer = Vectorizer( r=2, d=2 )\n",
      "    n_jobs = 1\n",
      "\n",
      "    graphs = pre_process( rfam_url( rfam_id ) )\n",
      "    X1 = vectorizer.transform( graphs, n_jobs = n_jobs )\n",
      "    describe(X1)\n",
      "    \n",
      "    from eden.modifier.fasta import fasta_to_fasta, shuffle_modifier\n",
      "    graphs = pre_process( fasta_to_fasta( rfam_url( rfam_id ) , modifier=shuffle_modifier, times=2, order=2) )\n",
      "    X2 = vectorizer.transform( graphs, n_jobs = n_jobs )\n",
      "    describe(X2)\n",
      "    \n",
      "    from eden.util import fit_estimator\n",
      "    estimator = fit_estimator( positive_data_matrix=X1, negative_data_matrix=X2 )\n",
      "    \n",
      "    return estimator, vectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "estimator_str, vectorizer_str = model(rfam_id, pre_process_rnashapes_struct)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 954 ; Features: 1048577 with an avg of 341 features per instance\n",
        "Instances: 1908 ; Features: 1048577 with an avg of 318 features per instance"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Classifier:\n",
        "SGDClassifier(alpha=5.48363616492e-05, class_weight='auto', epsilon=0.1,\n",
        "       eta0=8.19168589908, fit_intercept=True, l1_ratio=0.15,\n",
        "       learning_rate='invscaling', loss='hinge', n_iter=66, n_jobs=-1,\n",
        "       penalty='elasticnet', power_t=0.555614292793, random_state=None,\n",
        "       shuffle=True, verbose=0, warm_start=False)\n",
        "-------------------------------------------------------------------------\n",
        "Predictive performance:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "            accuracy: 0.973 +- 0.010\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "           precision: 0.965 +- 0.011\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "              recall: 0.955 +- 0.031\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                  f1: 0.960 +- 0.016\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   average_precision: 0.990 +- 0.006\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             roc_auc: 0.993 +- 0.006\n",
        "-------------------------------------------------------------------------\n",
        "CPU times: user 4min 30s, sys: 25.9 s, total: 4min 56s\n",
        "Wall time: 6min 56s\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "estimator, vectorizer = model(rfam_id, pre_process_rnashapes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 954 ; Features: 1048577 with an avg of 1032 features per instance\n",
        "Instances: 1908 ; Features: 1048577 with an avg of 980 features per instance"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Classifier:\n",
        "SGDClassifier(alpha=2.51877164708e-05, class_weight='auto', epsilon=0.1,\n",
        "       eta0=4.04620079072, fit_intercept=True, l1_ratio=0.15,\n",
        "       learning_rate='constant', loss='hinge', n_iter=96, n_jobs=-1,\n",
        "       penalty='elasticnet', power_t=0.648399169142, random_state=None,\n",
        "       shuffle=True, verbose=0, warm_start=False)\n",
        "-------------------------------------------------------------------------\n",
        "Predictive performance:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "            accuracy: 0.942 +- 0.054\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "           precision: 0.921 +- 0.111\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "              recall: 0.930 +- 0.065\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                  f1: 0.918 +- 0.063\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   average_precision: 0.989 +- 0.008\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             roc_auc: 0.993 +- 0.005\n",
        "-------------------------------------------------------------------------\n",
        "CPU times: user 7min 17s, sys: 1min 8s, total: 8min 25s\n",
        "Wall time: 15min 39s\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#use the compute_max_subarrays to return an iterable fasta containing the individual motives \n",
      "from eden.util.iterated_maximum_subarray import compute_max_subarrays\n",
      "\n",
      "def motives(iterable, min_subarray_size = None, max_subarray_size = None):\n",
      "    for graph in iterable:\n",
      "        subarrays = compute_max_subarrays(graph=graph, min_subarray_size=min_subarray_size, max_subarray_size=max_subarray_size)\n",
      "        if subarrays:\n",
      "            for subarray in subarrays:\n",
      "                yield ''.join(subarray['subarray'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.graph import Annotator\n",
      "annotator = Annotator( estimator = estimator, vectorizer = vectorizer )\n",
      "\n",
      "graphs = pre_process_rnashapes( rfam_url( rfam_id ) )\n",
      "graphs = annotator.transform( graphs )\n",
      "\n",
      "iterable = motives(graphs, min_subarray_size=5, max_subarray_size=18)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#collect all motives and return the unique occurrences\n",
      "motif_list = set(iterable)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 2min 20s, sys: 8.62 s, total: 2min 28s\n",
        "Wall time: 2min 56s\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#count occurrences of motives in original dataset\n",
      "from collections import defaultdict\n",
      "\n",
      "from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "iterable = fasta_to_fasta(rfam_url( rfam_id ), modifier=one_line_modifier, sequence_only=True)\n",
      "\n",
      "motif_counter = defaultdict(int)\n",
      "for seq in iterable:\n",
      "    for motif in motif_list:\n",
      "        if seq.find(motif) != -1:\n",
      "            motif_counter[motif] += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "motif_support_threshold = 2\n",
      "selcted_motifs = [motif for motif in motif_counter if motif_counter[motif] >= motif_support_threshold]    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Num: %d motives selected'%len(selcted_motifs)\n",
      "lens = [len(motif) for motif in selcted_motifs]\n",
      "#plot histogram of lengths\n",
      "plt.hist(lens, 10, histtype='stepfilled', facecolor='r', alpha=0.6)\n",
      "plt.grid()\n",
      "plt.title('Motives lenght distribution')\n",
      "plt.xlabel('size')\n",
      "plt.ylabel('frequency')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Num: 19 motives selected\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEZCAYAAAB/6SUgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmc68OwAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x111db67d0>"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "regex=''\n",
      "for m in sorted(selcted_motifs): regex += '|' + m\n",
      "regex = regex[1:]\n",
      "print regex"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "AAACCAA|AGAAAUA|GGUUCAA|GGUUCAAAU|GGUUCAAU|GGUUCGA|GGUUCGAA|GGUUCGAAU|GUUCAAAU|GUUCGAAU|UAAAGCA|UAAGUUCGA|UAGCUUAAA|UGGUUCAAAU|UGGUUCGA|UUCAAAU|UUCGAAU|UUGGUUC|UUGGUUCGA\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.modifier.fasta import fasta_to_fasta, keep_modifier, shuffle_modifier\n",
      "\n",
      "def motives_discriminative_performance_evaluation(data, regex):\n",
      "    iterable = fasta_to_fasta( data , modifier=keep_modifier, regex=regex )\n",
      "    true_positive_count = sum(1 for x in iterable)\n",
      "    iterable = fasta_to_fasta( data )\n",
      "    positive_count = sum(1 for x in iterable)\n",
      "    iterable = fasta_to_fasta( data , modifier=shuffle_modifier, times=20, order=2)\n",
      "    it1,it2 = itertools.tee(iterable)\n",
      "    negative_count = sum(1 for x in it1)\n",
      "    iterable = fasta_to_fasta( it2 , modifier=keep_modifier, regex=regex )\n",
      "    false_positive_count = sum(1 for x in iterable)\n",
      "    false_negative_count =  positive_count - true_positive_count\n",
      "    true_negative_count = negative_count - false_negative_count\n",
      "\n",
      "    recall = true_positive_count/float(true_positive_count + false_negative_count)\n",
      "    precision = true_positive_count/float(true_positive_count + false_positive_count)\n",
      "    f1 = 2 * precision * recall / (precision + recall)\n",
      "\n",
      "    print 'pos:%d neg:%d TP:%d FP:%d TN:%d FN:%d' % (positive_count, negative_count, true_positive_count, false_positive_count, true_negative_count, false_negative_count)\n",
      "    print 'precision:%0.3f recall:%0.3f f1:%0.3f' % (precision, recall, f1)\n",
      "    print 'dataset reduction: from %d to %d = %0.3f' % (negative_count, false_positive_count, false_positive_count/float(negative_count))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "motives_discriminative_performance_evaluation(rfam_url( rfam_id ), regex)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "pos:1908 neg:38160 TP:1296 FP:1578 TN:37548 FN:612\n",
        "precision:0.451 recall:0.679 f1:0.542\n",
        "dataset reduction: from 38160 to 1578 = 0.041\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#extract statistics on the average lenght of the sequences in the given Rfam family\n",
      "import numpy\n",
      "from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "\n",
      "low = 25\n",
      "high = 75\n",
      "\n",
      "iterable = fasta_to_fasta( rfam_url( rfam_id ), modifier=one_line_modifier, sequence_only=True)\n",
      "len_seqs = [len(seq) for seq in iterable]\n",
      "lower_quantile = int(numpy.percentile(len_seqs, low))\n",
      "upper_quantile = int(numpy.percentile(len_seqs, high))\n",
      "\n",
      "num_seqs = len(len_seqs)\n",
      "\n",
      "print 'Rfam family %s has %d sequences' % (rfam_id, num_seqs)\n",
      "print 'more than %d%% of the sequences have lenght smaller than: %d ' % (high, upper_quantile)\n",
      "print 'less then %d%% of the sequences have lenght smaller than: %d ' % (low, lower_quantile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Rfam family RF00005 has 954 sequences\n",
        "more than 75% of the sequences have lenght smaller than: 74 \n",
        "less then 25% of the sequences have lenght smaller than: 71 \n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.modifier.fasta import fasta_to_fasta, replace_modifier, split_regex_modifier, split_modifier, keep_modifier\n",
      "\n",
      "def genome_fasta_pre_processing(uri, min_lenght=None, max_lenght=None ):\n",
      "    #replace Ts with Us\n",
      "    iterable = fasta_to_fasta(uri, modifier=replace_modifier, regex='T', replacement='U')\n",
      "    #split out sequences that are not stretches of Ns  \n",
      "    iterable = fasta_to_fasta(iterable, modifier=split_regex_modifier, regex=\"([^N]+)\" )\n",
      "    #filter out small sequences, i.e. smaller than lower_quantile\n",
      "    iterable = fasta_to_fasta(iterable, modifier=keep_modifier, regex=\"(.{%d,})\"%min_lenght )\n",
      "    #split large sequences into overlapping windows of size comparable with the Rfam average seq lenght\n",
      "    iterable = fasta_to_fasta( iterable, modifier=split_modifier, window=max_lenght, step=int(max_lenght / 3) )\n",
      "    return iterable"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iterable = genome_fasta_pre_processing('dm6.fa.masked', min_lenght=lower_quantile, max_lenght=upper_quantile)\n",
      "iterable = fasta_to_fasta(iterable, modifier=keep_modifier, regex=regex )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "from datetime import datetime\n",
      "def parse_header(header):\n",
      "    '''process header to extract chromosome, start and end position'''\n",
      "    items = header[1:].split()\n",
      "    chromosome = items[0]\n",
      "    start = int(items[2])+int(items[4])\n",
      "    end = start + int(items[6])\n",
      "    seq = items[9]\n",
      "    id = '%s %d %d %s'%(chromosome,start,end,seq)\n",
      "    return id\n",
      "\n",
      "import sys\n",
      "f = open('result','a')\n",
      "print >> f, '-'*80\n",
      "print >> f, rfam_id\n",
      "print >> f, datetime.now() \n",
      "results = []\n",
      "for header, prediction in out_of_core_predictions( iterable, \n",
      "                                                  estimator=estimator_str, \n",
      "                                                  vectorizer=vectorizer_str, \n",
      "                                                  pre_process=pre_process_rnashapes_struct, \n",
      "                                                  threshold=2 ):\n",
      "    id = parse_header( header )\n",
      "    #save and display results\n",
      "    results.append([id, prediction])\n",
      "    result_text = 'score: %0.1f %s' % (prediction,id)\n",
      "    print result_text\n",
      "    sys.stdout.flush()\n",
      "    print >> f, result_text\n",
      "    f.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 2.0 chr2L 32747889 32750793 UUUGGUUCGUAUAUGAAAAAAUACCAAAAUCGGUUAAUGUUUAUUGAAAAAGCAUAAAAUUCGUUCUACCAGAA\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 2.3 chr2R 19857810 19858506 GAAUGAAAAUCUUUCUACCCAUUUCGCAAAGGUACUUUGGUUUUAAAAACUAGUUUUCAAACCAAAAACAUUCC\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 2.4 chr2R 28411051 28411243 CAGUGCUCCUUAGCCCCAUCUGAAUGUACGGACCCUGGCUGGAAGGUUCGAUAAUUUAUUGAGGGUUUCGCUGU\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 2.1 chr3L 35639958 35640606 UAUCGAUAAAUUCACUUGUUUUUUUUUUUUUAAAGUUACACAGUAAACCAAACGGAGGUCAUUUAACUCGAUGA\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 2.2 chr3R 3536049 3536697 UGGUUCCGGCUAUAUAGUCGGUAAAAUCCUUGAGUCACGCGCUCGAAAAUUUUCAAAUCUUAAAUAAAAACCAC\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 2.1 chr3R 21379270 21380566 AAGCAUUCUUUCAAUUAGGGGAAUUCACACAGAUUAUAAUAGAAACCAAAUAUACUGGAUCAAUAAAGUGCUUU\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 2.2 chr3R 27737403 27737595 AUUUAAAUUUAAAGCAACCAUUUUGUGACCAACGCUUCGAGUCUCUCCAUUCUAACCCCUGUUUAGUAUAAAUA\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 2.1 chr3R 35970103 35971039 AAUGCUGCUACUUUUAUUUAUAGAAAUAAUUACUAAAGUAAGGUUCUCAAAUUAAAGGGAAUUUGUAUGCAUUU\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 2.2 chrX 12604078 12604198 CAUGAUUGAUGUUCCAGGAUGCAUGAAGAAAUAUUUGAUUGAAGUGGCUCUCAACUAGUGUGUUGCAAUUAUGC\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 2.0 chrX 30534926 30535334 CAUUUCGAUUCAAAUGCGUUUGGGUGUGGGCUAAAAUUUACAUUUAUUUAAUUUGCCCCGGUACGGAGAAAUGC\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 2.0 chrX 31345669 31348765 UGGGAAAAAGUCGUAAAGAACUCAAAUUGGUUCAAUAUGUCUAAUAUAUAUAUAUGCAGCAAUGAUUUUUCCUU\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 4h 38min 13s, sys: 25min 32s, total: 5h 3min 45s\n",
        "Wall time: 6h 19min 38s\n"
       ]
      }
     ],
     "prompt_number": 38
    }
   ],
   "metadata": {}
  }
 ]
}