{
 "metadata": {
  "name": "",
  "signature": "sha256:1d7a97633ad1cc61994050185fc93390207df9cca6ffd64636a9d7ce118a64a8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "auxiliary functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#concatenate the two data matrices into one matrix\n",
      "#and we create a target vector that identifies with +1 and -1 the instances from the first or the second RNA family\n",
      "from scipy.sparse import vstack\n",
      "import numpy as np\n",
      "\n",
      "def make_data_matrix(X1,X2):\n",
      "    #create target array\n",
      "    yp =  [1] * X1.shape[0]\n",
      "    yn = [-1] * X2.shape[0]\n",
      "    y = np.array(yp + yn)\n",
      "    #compose data matrix\n",
      "    X = vstack( [X1,X2] , format = \"csr\")\n",
      "    return X,y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def out_of_core_predict(data, estimator = None, vectorizer = None):\n",
      "    from eden.graph import OutOfCoreListPredictor\n",
      "    estimator\n",
      "    vectorizer\n",
      "    out_of_core_predictor = OutOfCoreListPredictor( estimator = estimator, vectorizer = vectorizer )\n",
      "\n",
      "    #extract oneline fasta\n",
      "    from eden.modifier.fasta import fasta_to_fasta, remove_modifier\n",
      "    seqs = fasta_to_fasta( data, modifier = remove_modifier, remove_char = '-' )\n",
      "    from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "    fasta_seqs = fasta_to_fasta( seqs, modifier = one_line_modifier, one_line = True, one_line_separator = '\\t' )\n",
      "\n",
      "    #extract graphs\n",
      "    graphs_list, weights = pre_process( data )\n",
      "\n",
      "    #sort and store prediction-fasta pairs\n",
      "    import itertools as it \n",
      "    results = sorted([(line, prediction) for line, prediction in it.izip(fasta_seqs, out_of_core_predictor.predict(graphs_list, weights = weights))], key=lambda val: val[1] , reverse=True)\n",
      "\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "\n",
      "def make_iterable( data ):\n",
      "    #check if data is iterable\n",
      "    if hasattr( data, '__iter__' ):\n",
      "        iterable = data\n",
      "    else: #if not then process url or file with fasta_to_fasta\n",
      "        from eden.modifier.fasta import fasta_to_fasta\n",
      "        iterable = fasta_to_fasta( data )\n",
      "    return iterable\n",
      "\n",
      "\n",
      "def _pre_process( data, pre_processes, weights):\n",
      "    iterable = make_iterable( data )\n",
      "    graphs_list = list()\n",
      "    assert(len(weights) == len(pre_processes)),'Different lengths'\n",
      "    #NOTE: we have to duplicate the sequences iterator if we want to use different modifiers in parallel\n",
      "    iterables = itertools.tee( iterable, len(pre_processes) )\n",
      "    for pre_process_item, iterable_item in zip(pre_processes, iterables):\n",
      "        graphs_list.append( pre_process_item( iterable_item ) )\n",
      "    return (graphs_list, weights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Domain specific conversion"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#data sources\n",
      "posf  = 'http://share.gruenings.eu/schilling/mmp2-training-final_noMinus.fasta'\n",
      "negf  = 'http://share.gruenings.eu/schilling/human-shuffled.fasta'\n",
      "testf = 'http://share.gruenings.eu/schilling//Mmp2-CTSL-VALIDATE-final_noMinue.fasta'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from urllib import urlretrieve\n",
      "import pickle\n",
      "urlretrieve (\"http://www.bioinf.uni-freiburg.de/~costa/BLOSUM62_5D_encoding_dict.p\", \"BLOSUM62_5D_encoding_dict.p\")\n",
      "aa_encoding_dict5D = pickle.load( open( \"BLOSUM62_5D_encoding_dict.p\", \"rb\" ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#add encoding for landmarks\n",
      "landmark_encodings = {'%':[10,0,0,0,0], '#':[0,10,0,0,0], '$':[0,0,10,0,0]}\n",
      "aa_encoding_dict5D.update(landmark_encodings)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_jobs = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_aa_categorical( data ):\n",
      "    iterable = make_iterable( data )\n",
      "    #skip fasta entries that contain the '-' symbol\n",
      "    from eden.modifier.fasta import fasta_to_fasta, remove_modifier\n",
      "    seqs = fasta_to_fasta( iterable, modifier = remove_modifier, remove_char = '-' )\n",
      "    \n",
      "    #insert landmark in the cleavage site after pos 4, in our case this means always in the middle position\n",
      "    from eden.modifier.fasta import fasta_to_fasta, insert_landmark_modifier\n",
      "    seqs = fasta_to_fasta( seqs, modifier = insert_landmark_modifier, landmark_relative_position = 0.5, landmark_char = '%' )\n",
      "    seqs = fasta_to_fasta( seqs, modifier = insert_landmark_modifier, landmark_relative_position = 0, landmark_char = '#' )\n",
      "    seqs = fasta_to_fasta( seqs, modifier = insert_landmark_modifier, landmark_relative_position = 1, landmark_char = '$' )\n",
      "\n",
      "    #convert to graph\n",
      "    from eden.converter.fasta import fasta_to_eden\n",
      "    graphs = fasta_to_eden( seqs )\n",
      "    \n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_aa_smoothed( data ):\n",
      "    iterable = make_iterable( data )\n",
      "    \n",
      "    #skip fasta entries that contain the '-' symbol\n",
      "    from eden.modifier.fasta import fasta_to_fasta, remove_modifier\n",
      "    seqs = fasta_to_fasta( iterable, modifier = remove_modifier, remove_char = '-' )\n",
      "    \n",
      "    #insert landmark in the cleavage site after pos 4, in our case this means always in the middle position\n",
      "    from eden.modifier.fasta import fasta_to_fasta, insert_landmark_modifier\n",
      "    seqs = fasta_to_fasta( seqs, modifier = insert_landmark_modifier, landmark_relative_position = 0.5, landmark_char = '%' )\n",
      "    seqs = fasta_to_fasta( seqs, modifier = insert_landmark_modifier, landmark_relative_position = 0, landmark_char = '#' )\n",
      "    seqs = fasta_to_fasta( seqs, modifier = insert_landmark_modifier, landmark_relative_position = 1, landmark_char = '$' )\n",
      "\n",
      "    #convert to graph\n",
      "    from eden.converter.fasta import fasta_to_eden\n",
      "    graphs = fasta_to_eden( seqs )\n",
      "    \n",
      "    #relabel aa with vector encoding\n",
      "    from eden.modifier.graph.vertex_attributes import translate \n",
      "    graphs = translate(graphs, label_map = aa_encoding_dict5D, default = [0,0,0,0,0])\n",
      "    \n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process( data ):\n",
      "    weights = [0.7, 0.3]\n",
      "    pre_processes = [pre_process_aa_categorical, pre_process_aa_smoothed]\n",
      "    return _pre_process( data, pre_processes, weights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#set the 'resolution' of the vectorization\n",
      "from eden.graph import ListVectorizer\n",
      "vectorizer = ListVectorizer( r = 2, d = 5, min_r = 0, discretization_size = 5, discretization_dimension = 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "graphs_list, weights = pre_process( posf )\n",
      "vectorizer.fit( graphs_list, n_jobs = n_jobs )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "graphs_list, weights = pre_process( posf )\n",
      "X1 = vectorizer.transform( graphs_list, weights = weights, n_jobs = n_jobs )\n",
      "print 'Instances: %d ; Features: %d with an avg of %d features per instance' % (X1.shape[0], X1.shape[1],  X1.getnnz()/X1.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 605 ; Features: 1048577 with an avg of 1147 features per instance\n",
        "CPU times: user 1min 4s, sys: 722 ms, total: 1min 5s\n",
        "Wall time: 1min 5s\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Library/Python/2.7/site-packages/sklearn/cluster/k_means_.py:798: RuntimeWarning: Got data type int64, converted to float to avoid overflows\n",
        "  X = self._check_test_data(X)\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "from eden.modifier.fasta import fasta_to_fasta, shuffle_modifier\n",
      "graphs_list, weights = pre_process( fasta_to_fasta( posf, modifier = shuffle_modifier, times = 2, order = 2 ) )\n",
      "X2 = vectorizer.transform( graphs_list, weights = weights, n_jobs = n_jobs )\n",
      "print 'Instances: %d ; Features: %d with an avg of %d features per instance' % (X2.shape[0], X2.shape[1],  X2.getnnz()/X2.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 1210 ; Features: 1048577 with an avg of 1145 features per instance\n",
        "CPU times: user 2min 12s, sys: 1.88 s, total: 2min 14s\n",
        "Wall time: 2min 13s\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "from eden.util import estimate_predictive_performance\n",
      "X,y = make_data_matrix(X1,X2)\n",
      "estimator = estimate_predictive_performance(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Classifier:\n",
        "SGDClassifier(alpha=0.00033630027515, class_weight='auto', epsilon=0.1,\n",
        "       eta0=6.03995555775, fit_intercept=True, l1_ratio=0.15,\n",
        "       learning_rate='invscaling', loss='hinge', n_iter=38, n_jobs=-1,\n",
        "       penalty='l2', power_t=0.327710915779, random_state=None,\n",
        "       shuffle=True, verbose=0, warm_start=False)\n",
        "-------------------------------------------------------------------------\n",
        "Predictive performance:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "            accuracy: 0.820 +- 0.046\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "           precision: 0.716 +- 0.053\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "              recall: 0.757 +- 0.172\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                  f1: 0.727 +- 0.105\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   average_precision: 0.764 +- 0.104\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             roc_auc: 0.891 +- 0.050\n",
        "-------------------------------------------------------------------------\n",
        "CPU times: user 24.5 s, sys: 32.7 s, total: 57.2 s\n",
        "Wall time: 4min 23s\n"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "results = out_of_core_predict(negf, estimator = estimator, vectorizer = vectorizer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#extract top-k difficult sequences\n",
      "negative_to_positive_ratio = 10\n",
      "num_pos = X1.shape[0]\n",
      "num = int( num_pos * negative_to_positive_ratio )\n",
      "print 'Selecting top %d most difficult to discriminate instances'%num\n",
      "from itertools import chain\n",
      "selected_seqs = list(chain.from_iterable(line.split('\\t') for line, prediction in results[:num]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "graphs_list, weights = pre_process( selected_seqs )\n",
      "X3 = vectorizer.transform( graphs_list, weights = weights, n_jobs = n_jobs )\n",
      "print 'Instances: %d ; Features: %d with an avg of %d features per instance' % (X3.shape[0], X3.shape[1],  X3.getnnz()/X3.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "X,y = make_data_matrix(X1,X3)\n",
      "estimator2 = estimate_predictive_performance(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "results2 = out_of_core_predict(testf, estimator = estimator2, vectorizer = vectorizer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ipy_table import * \n",
      "\n",
      "mat=[('ID','Conf')]\n",
      "mat += results2\n",
      "make_table(mat)\n",
      "apply_theme('basic')\n",
      "set_global_style(float_format = '%0.3f')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "results = out_of_core_predict(testf, estimator = estimator, vectorizer = vectorizer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ipy_table import * \n",
      "\n",
      "mat=[('ID','Conf')]\n",
      "mat += results\n",
      "make_table(mat)\n",
      "apply_theme('basic')\n",
      "set_global_style(float_format = '%0.3f')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}