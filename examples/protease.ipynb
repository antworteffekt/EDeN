{
 "metadata": {
  "name": "",
  "signature": "sha256:ffd9689e20144e1974f8dccf1de88d3b47b312d49163b71d17c38f0b030aa152"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import pylab as pl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING: pylab import has clobbered these variables: ['vstack']\n",
        "`%matplotlib` prevents importing * from pylab and numpy\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "auxiliary functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#concatenate the two data matrices into one matrix\n",
      "#and we create a target vector that identifies with +1 and -1 the instances from the first or the second RNA family\n",
      "from scipy.sparse import vstack\n",
      "import numpy as np\n",
      "\n",
      "def make_data_matrix(X1,X2):\n",
      "    #create target array\n",
      "    yp =  [1] * X1.shape[0]\n",
      "    yn = [-1] * X2.shape[0]\n",
      "    y = np.array(yp + yn)\n",
      "    #update data matrix\n",
      "    X = vstack( [X1,X2] , format = \"csr\")\n",
      "    return X,y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def out_of_core_predict(data, estimator = None, vectorizer = None):\n",
      "    from eden.graph import OutOfCoreListPredictor\n",
      "    estimator\n",
      "    vectorizer\n",
      "    out_of_core_predictor = OutOfCoreListPredictor( estimator = estimator, vectorizer = vectorizer )\n",
      "\n",
      "    #extract oneline fasta\n",
      "    from eden.modifier.fasta import fasta_to_fasta, remove_modifier\n",
      "    seqs = fasta_to_fasta( data, modifier = remove_modifier, remove_char = '-' )\n",
      "    from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "    fasta_seqs = fasta_to_fasta( seqs, modifier = one_line_modifier, one_line = True, one_line_separator = '\\t' )\n",
      "\n",
      "    #extract graphs\n",
      "    graphs_list, weights = pre_process( data )\n",
      "\n",
      "    #sort and store prediction-fasta pairs\n",
      "    import itertools as it \n",
      "    results = sorted([(line, prediction) for line, prediction in it.izip(fasta_seqs, out_of_core_predictor.predict(graphs_list, weights = weights))], key=lambda val: val[1] , reverse=True)\n",
      "\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Domain specific conversion"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#data sources\n",
      "posf  = 'http://share.gruenings.eu/schilling/mmp2-training-final_noMinus.fasta'\n",
      "negf  = 'http://share.gruenings.eu/schilling/human-shuffled.fasta'\n",
      "testf = 'http://share.gruenings.eu/schilling//Mmp2-CTSL-VALIDATE-final_noMinue.fasta'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from urllib import urlretrieve\n",
      "import pickle\n",
      "urlretrieve (\"http://www.bioinf.uni-freiburg.de/~costa/BLOSUM62_5D_encoding_dict.p\", \"BLOSUM62_5D_encoding_dict.p\")\n",
      "aa_encoding_dict5D = pickle.load( open( \"BLOSUM62_5D_encoding_dict.p\", \"rb\" ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#add encoding for landmarks\n",
      "landmark_encodings = {'%':[10,0,0,0,0], '#':[0,10,0,0,0], '$':[0,0,10,0,0]}\n",
      "aa_encoding_dict5D.update(landmark_encodings)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_jobs = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "\n",
      "def pre_process( data ):\n",
      "\n",
      "    from eden.modifier.fasta import fasta_to_fasta\n",
      "    iterable = fasta_to_fasta( data )\n",
      "\n",
      "    #NOTE: we have to duplicate the sequences iterator if we want to use different modifiers in parallel\n",
      "    num = 2\n",
      "    iterables = itertools.tee( iterable, num )\n",
      "    \n",
      "    graphs_list = list()\n",
      "    weights = list()\n",
      "    \n",
      "    #------------------------------------------------------\n",
      "    #1 aminoacid categorical labels\n",
      "    \n",
      "    #skip fasta entries that contain the '-' symbol\n",
      "    from eden.modifier.fasta import fasta_to_fasta, remove_modifier\n",
      "    seqs = fasta_to_fasta( iterables[0], modifier = remove_modifier, remove_char = '-' )\n",
      "    \n",
      "    #insert landmark in the cleavage site after pos 4, in our case this means always in the middle position\n",
      "    from eden.modifier.fasta import fasta_to_fasta, insert_landmark_modifier\n",
      "    seqs = fasta_to_fasta( seqs, modifier = insert_landmark_modifier, landmark_relative_position = 0.5, landmark_char = '%' )\n",
      "    seqs = fasta_to_fasta( seqs, modifier = insert_landmark_modifier, landmark_relative_position = 0, landmark_char = '#' )\n",
      "    seqs = fasta_to_fasta( seqs, modifier = insert_landmark_modifier, landmark_relative_position = 1, landmark_char = '$' )\n",
      "\n",
      "    from eden.converter.fasta import fasta_to_eden\n",
      "    graphs = fasta_to_eden( seqs )\n",
      "    \n",
      "    graphs_list.append(graphs)\n",
      "    weights.append(0.7)\n",
      "\n",
      "\n",
      "    #------------------------------------------------------    \n",
      "    #2 aminoacid vector labels\n",
      "    \n",
      "    #skip fasta entries that contain the '-' symbol\n",
      "    from eden.modifier.fasta import fasta_to_fasta, remove_modifier\n",
      "    seqs = fasta_to_fasta( iterables[1], modifier = remove_modifier, remove_char = '-' )\n",
      "    \n",
      "    #insert landmark in the cleavage site after pos 4, in our case this means always in the middle position\n",
      "    from eden.modifier.fasta import fasta_to_fasta, insert_landmark_modifier\n",
      "    seqs = fasta_to_fasta( seqs, modifier = insert_landmark_modifier, landmark_relative_position = 0.5, landmark_char = '%' )\n",
      "    seqs = fasta_to_fasta( seqs, modifier = insert_landmark_modifier, landmark_relative_position = 0, landmark_char = '#' )\n",
      "    seqs = fasta_to_fasta( seqs, modifier = insert_landmark_modifier, landmark_relative_position = 1, landmark_char = '$' )\n",
      "\n",
      "    from eden.converter.fasta import fasta_to_eden\n",
      "    graphs = fasta_to_eden( seqs )\n",
      "    \n",
      "    from eden.modifier.graph.vertex_attributes import translate \n",
      "    graphs = translate(graphs, label_map = aa_encoding_dict5D, default = [0,0,0,0,0])\n",
      "    \n",
      "    graphs_list.append(graphs)\n",
      "    weights.append(0.3)\n",
      "\n",
      "\n",
      "    return (graphs_list, weights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#set the 'resolution' of the vectorization\n",
      "from eden.graph import ListVectorizer\n",
      "vectorizer = ListVectorizer( r = 2, d = 5, min_r = 0, discretization_size = 5, discretization_dimension = 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "graphs_list, weights = pre_process( posf )\n",
      "vectorizer.fit( graphs_list, n_jobs = n_jobs )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "graphs_list, weights = pre_process( posf )\n",
      "X1 = vectorizer.transform( graphs_list, weights = weights, n_jobs = n_jobs )\n",
      "print 'Instances: %d ; Features: %d with an avg of %d features per instance' % (X1.shape[0], X1.shape[1],  X1.getnnz()/X1.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 605 ; Features: 1048577 with an avg of 1147 features per instance\n",
        "CPU times: user 1min 3s, sys: 820 ms, total: 1min 4s\n",
        "Wall time: 1min 4s\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Library/Python/2.7/site-packages/sklearn/cluster/k_means_.py:798: RuntimeWarning: Got data type int64, converted to float to avoid overflows\n",
        "  X = self._check_test_data(X)\n"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "from eden.modifier.fasta import fasta_to_fasta, shuffle_modifier\n",
      "graphs_list, weights = pre_process( fasta_to_fasta( posf, modifier = shuffle_modifier, times = 2, order = 2 ) )\n",
      "X2 = vectorizer.transform( graphs_list, weights = weights, n_jobs = n_jobs )\n",
      "print 'Instances: %d ; Features: %d with an avg of %d features per instance' % (X2.shape[0], X2.shape[1],  X2.getnnz()/X2.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "from eden.util import estimate_predictive_performance\n",
      "X,y = make_data_matrix(X1,X2)\n",
      "estimator = estimate_predictive_performance(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "results = out_of_core_predict(negf, estimator = estimator, vectorizer = vectorizer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#extract top-k difficult sequences\n",
      "negative_to_positive_ratio = 10\n",
      "num_pos = X1.shape[0]\n",
      "num = int( num_pos * negative_to_positive_ratio )\n",
      "print 'Selecting top %d most difficult to discriminate instances'%num\n",
      "from itertools import chain\n",
      "selected_seqs = list(chain.from_iterable(line.split('\\t') for line, prediction in results[:num]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "graphs_list, weights = pre_process( selected_seqs )\n",
      "X3 = vectorizer.transform( graphs_list, weights = weights, n_jobs = n_jobs )\n",
      "print 'Instances: %d ; Features: %d with an avg of %d features per instance' % (X3.shape[0], X3.shape[1],  X3.getnnz()/X3.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "X,y = make_data_matrix(X1,X3)\n",
      "estimator2 = estimate_predictive_performance(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results2 = out_of_core_predict(testf, estimator = estimator2, vectorizer = vectorizer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ipy_table import * \n",
      "\n",
      "mat=[('ID','Conf')]\n",
      "mat += results2\n",
      "make_table(mat)\n",
      "apply_theme('basic')\n",
      "set_global_style(float_format = '%0.3f')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results3 = out_of_core_predict(testf, estimator = estimator, vectorizer = vectorizer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ipy_table import * \n",
      "\n",
      "mat=[('ID','Conf')]\n",
      "mat += results3\n",
      "make_table(mat)\n",
      "apply_theme('basic')\n",
      "set_global_style(float_format = '%0.3f')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}