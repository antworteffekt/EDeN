{
 "metadata": {
  "name": "",
  "signature": "sha256:ae349516ae8aaf03fcfbcd2c0ea052af7ab035eab21a345f97e4082b80d0887b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Classification"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Consider a binary classification problem. The data and target files are available online. The domain of the problem is chemoinformatics. Data is about toxicity of 4K small molecules.\n",
      "The creation of a predictive system happens in 3 steps:\n",
      "\n",
      "1. *data conversion*: transform instances into a suitable graph format. This is done using specialized programs for each (domain, format) pair. In the example we have molecular graphs encoded using the gSpan format and we will therefore use the 'gspan' tool.\n",
      "\n",
      "2. *data vectorization*: transform graphs into sparse vectors. This is done using the EDeN tool. The vectorizer accepts as parameters the (maximal) size of the fragments to be used as features, this is expressed as the pair 'radius' and the 'distance'. See for details: F. Costa, K. De Grave,''Fast Neighborhood Subgraph Pairwise Distance Kernel'', 27th International Conference on Machine Learning (ICML), 2010.\n",
      "\n",
      "3. *modelling*: fit a predicitve system and evaluate its performance. This is done using the tools offered by the scikit library. In the example we will use a Stochastic Gradient Descent linear classifier.\n",
      "\n",
      "In the following cells there is the code for each step."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Install the library "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "1 Conversion"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "load a target file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "input_target_url='http://www.bioinf.uni-freiburg.de/~costa/bursi.target'\n",
      "from eden.util import eden_io\n",
      "y=eden_io.load_target(input_target_url)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "load data and convert it to graphs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#load data\n",
      "input_data_url='http://www.bioinf.uni-freiburg.de/~costa/bursi.gspan'\n",
      "from eden.converter.graph import gspan\n",
      "g_it=gspan.gspan_to_eden(input = input_data_url, input_type = 'url')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2 Vectorization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "setup the vectorizer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#parameters setting\n",
      "max_radius=3\n",
      "min_radius=0\n",
      "max_distance=3\n",
      "\n",
      "from eden import graph\n",
      "vec=graph.Vectorizer(r=max_radius,d=max_distance, min_r=min_radius)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "extract features and build data matrix"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "X=vec.transform(g_it, n_jobs=-1)\n",
      "print 'Instances: %d Features: %d with an avg of %d features per instance' % (X.shape[0], X.shape[1],  X.getnnz()/X.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 4337 Features: 1048577 with an avg of 312 features per instance\n",
        "CPU times: user 19.7 s, sys: 1.98 s, total: 21.7 s\n",
        "Wall time: 21.9 s\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3 Modelling"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Induce a predictor and evaluate its performance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#induce a predictive model\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "predictor = SGDClassifier()\n",
      "\n",
      "from sklearn import cross_validation\n",
      "scores = cross_validation.cross_val_score(predictor, X, y,cv=10, scoring='roc_auc')\n",
      "\n",
      "import numpy as np\n",
      "print('AUC ROC: %.4f +- %.4f' % (np.mean(scores),np.std(scores)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "AUC ROC: 0.9050 +- 0.0160\n",
        "CPU times: user 1.33 s, sys: 180 ms, total: 1.51 s\n",
        "Wall time: 1.51 s\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#induce a stochastic gradient descent SVM predictive model\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.grid_search import RandomizedSearchCV\n",
      "from sklearn import cross_validation\n",
      "from scipy.stats import randint\n",
      "from scipy.stats import uniform\n",
      "import numpy as np\n",
      "from scipy import stats\n",
      "\n",
      "predictor = SGDClassifier()\n",
      "#hyperparameter optimization\n",
      "param_dist = {\"n_iter\": randint(5, 100),\n",
      "              \"power_t\": uniform(0.1),\n",
      "              \"alpha\": uniform(1e-08,1e-03),\n",
      "              \"eta0\" : uniform(1e-03,10),\n",
      "              \"penalty\": [\"l1\", \"l2\", \"elasticnet\"],\n",
      "              \"learning_rate\": [\"invscaling\", \"constant\",\"optimal\"]}\n",
      "scoring = 'roc_auc'\n",
      "n_iter_search = 20\n",
      "random_search = RandomizedSearchCV(predictor,param_distributions=param_dist,n_iter=n_iter_search,cv=5,scoring=scoring,n_jobs=8)\n",
      "random_search.fit(X, y)\n",
      "optpredictor= SGDClassifier(shuffle=True, n_jobs=-1, **random_search.best_params_)\n",
      "#fit the predictor on all available data\n",
      "optpredictor.fit(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 8.22 s, sys: 8.24 s, total: 16.5 s\n",
        "Wall time: 52.5 s\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "print 'Classifier:'\n",
      "print optpredictor\n",
      "print '-'*80\n",
      "\n",
      "print 'Predictive performance:'\n",
      "#assess the generalization capacity of the model via a 10-fold cross validation\n",
      "for scoring in ['precision', 'recall', 'f1', 'average_precision', 'roc_auc']:\n",
      "    scores = cross_validation.cross_val_score(optpredictor, X, y,cv=10, scoring=scoring, n_jobs=8)\n",
      "    print('%20s: %.3f +- %.3f' % (scoring, np.mean(scores),np.std(scores)))\n",
      "print '-'*80"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Classifier:\n",
        "SGDClassifier(alpha=0.000266915912685, class_weight=None, epsilon=0.1,\n",
        "       eta0=7.2653995017, fit_intercept=True, l1_ratio=0.15,\n",
        "       learning_rate='optimal', loss='hinge', n_iter=90, n_jobs=-1,\n",
        "       penalty='l2', power_t=0.644527209288, random_state=None,\n",
        "       shuffle=True, verbose=0, warm_start=False)\n",
        "--------------------------------------------------------------------------------\n",
        "Predictive performance:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "           precision: 0.856 +- 0.023\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "              recall: 0.855 +- 0.033\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                  f1: 0.855 +- 0.015\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   average_precision: 0.918 +- 0.016\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             roc_auc: 0.908 +- 0.012\n",
        "--------------------------------------------------------------------------------\n",
        "CPU times: user 2.59 s, sys: 3.72 s, total: 6.31 s\n",
        "Wall time: 30.3 s\n"
       ]
      }
     ],
     "prompt_number": 16
    }
   ],
   "metadata": {}
  }
 ]
}