{
 "metadata": {
  "name": "",
  "signature": "sha256:ac75f6e9b81ff22bdab0602b891d86a166ecada1d08238084c2e58d948cde229"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden import graph\n",
      "from eden.util import io\n",
      "from eden.converters import gspan"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn import cross_validation\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " help(graph.Vectorizer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Help on class Vectorizer in module eden.graph:\n",
        "\n",
        "class Vectorizer(__builtin__.object)\n",
        " |  Transforms graphs in sparse vectors.\n",
        " |  \n",
        " |  Methods defined here:\n",
        " |  \n",
        " |  __init__(self, r=3, d=3, nbits=20, normalization=True, inner_normalization=True, additional_pure_neighborhood_features=False, weighted=False)\n",
        " |      Parameters\n",
        " |      ----------\n",
        " |      r : int \n",
        " |          The radius size.\n",
        " |      \n",
        " |      d : int \n",
        " |          The distance size.\n",
        " |      \n",
        " |      nbits : int \n",
        " |          The number of bits that defines the feature space size: |feature space|=2^nbits.\n",
        " |      \n",
        " |      normalization : bool \n",
        " |          If set the resulting feature vector will have unit euclidean norm.\n",
        " |      \n",
        " |      inner_normalization : bool \n",
        " |          If set the feature vector for a specific combination of the radius and \n",
        " |          distance size will have unit euclidean norm.\n",
        " |          When used together with the 'normalization' flag it will be applied first and \n",
        " |          then the resulting feature vector will be normalized.\n",
        " |      \n",
        " |      additional_pure_neighborhood_features : bool \n",
        " |          If set additional features are going to be generated. \n",
        " |          These features are generated in a similar fashion as the original features, \n",
        " |          with the caveat that the first neighborhood is omitted.\n",
        " |          The purpose of these features is to allow vertices that have similar contexts to be \n",
        " |          matched, even when they are completely different. \n",
        " |      \n",
        " |      weighted : bool \n",
        " |          If set the occurrence of each neighborhood is weighted by \n",
        " |          aritmetic_mean(w(V))*geometric_mean(w(E)), where w(V) is the weight function for the \n",
        " |          vertices and w(E) is the weight function for the edges.\n",
        " |  \n",
        " |  fit(self, G_list, kernel_dict, hasher_dict, n_jobs=1)\n",
        " |      Constructs an approximate explicit mapping of a kernel function on the data \n",
        " |      stored in the nodes of the graphs.\n",
        " |      The 'kernel_dict' dictionary specifies the appropriate approximate kernel mapping \n",
        " |      strategy for different node 'classes'. The 'hasher_dict' specifies the locality sensitive \n",
        " |      hashing strategy to discretize the resulting approximate kernel mapping.\n",
        " |      \n",
        " |      Parameters\n",
        " |      ----------\n",
        " |      G_list : list of networkx graphs. \n",
        " |          The data.\n",
        " |      \n",
        " |      kernel_dict : list of approximate mappers. \n",
        " |          The key matches the 'class' of nodes. The assocaited value is \n",
        " |          a pair (kernel approximation callable, parameters).\n",
        " |      \n",
        " |      hasher_dict : list of localoty sensitive hashing (LSH) functions.\n",
        " |          The key matches the 'class' of nodes. The assocaited value is \n",
        " |          a pair (LSH callable, parameters).\n",
        " |      \n",
        " |      n_jobs : integer, optional\n",
        " |          Number of jobs to run in parallel (default 1).\n",
        " |  \n",
        " |  fit_transform(self, G_list, kernel_dict, hasher_dict, n_jobs=1)\n",
        " |      Constructs an approximate explicit mapping of a kernel function on the data \n",
        " |      stored in the nodes of the graphs and then transforms a list of networkx graphs \n",
        " |      into a Numpy csr sparse matrix (Compressed Sparse Row matrix).\n",
        " |      \n",
        " |      The 'kernel_dict' dictionary specifies the appropriate approximate kernel mapping \n",
        " |      strategy for different node 'classes'. The 'hasher_dict' specifies the locality sensitive \n",
        " |      hashing strategy to discretize the resulting approximate kernel mapping.\n",
        " |      \n",
        " |      Parameters\n",
        " |      ----------\n",
        " |      G_list : list of networkx graphs. \n",
        " |          The data.\n",
        " |      \n",
        " |      kernel_dict : list of approximate mappers. \n",
        " |          The key matches the 'class' of nodes. The assocaited value is \n",
        " |          a pair (kernel approximation callable, parameters).\n",
        " |      \n",
        " |      hasher_dict : list of localoty sensitive hashing (LSH) functions.\n",
        " |          The key matches the 'class' of nodes. The assocaited value is \n",
        " |          a pair (LSH callable, parameters).\n",
        " |      \n",
        " |      n_jobs : integer, optional\n",
        " |          Number of jobs to run in parallel (default 1).\n",
        " |  \n",
        " |  transform(self, G_list, n_jobs=1)\n",
        " |      Transforms a list of networkx graphs into a Numpy csr sparse matrix \n",
        " |      (Compressed Sparse Row matrix).\n",
        " |      \n",
        " |      Parameters\n",
        " |      ----------\n",
        " |      G_list : list of networkx graphs. \n",
        " |          The data.\n",
        " |      \n",
        " |      n_jobs : integer, optional\n",
        " |          Number of jobs to run in parallel (default 1).\n",
        " |  \n",
        " |  transform_iter(self, G_list)\n",
        " |      Transforms a list of networkx graphs into a Numpy csr sparse matrix \n",
        " |      (Compressed Sparse Row matrix) and returns one sparse row at a time.\n",
        " |      This is a generator.\n",
        " |  \n",
        " |  ----------------------------------------------------------------------\n",
        " |  Data descriptors defined here:\n",
        " |  \n",
        " |  __dict__\n",
        " |      dictionary for instance variables (if defined)\n",
        " |  \n",
        " |  __weakref__\n",
        " |      list of weak references to the object (if defined)\n",
        " |  \n",
        " |  ----------------------------------------------------------------------\n",
        " |  Data and other attributes defined here:\n",
        " |  \n",
        " |  __slotnames__ = []\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "help(io.load_target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Help on function load_target in module eden.util.io:\n",
        "\n",
        "load_target(name, input_type='url')\n",
        "    Return a numpy array of integers to be used as target vector.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    name : string\n",
        "        A pointer to the data source.\n",
        "    \n",
        "    input_type : ['url','file','string_file']\n",
        "        If type is 'url' then 'name' is interpreted as a URL pointing to a file.\n",
        "        If type is 'file' then 'name' is interpreted as a file name.\n",
        "        If type is 'string_file' then 'name' is interpreted as a file name for a file \n",
        "        that contains strings rather than integers. The set of strings are mapped to \n",
        "        unique increasing integers and the corresponding vector of integers is returned.\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Create Feature Representation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_radius=4\n",
      "max_distance=4\n",
      "input_data_url='http://www.bioinf.uni-freiburg.de/~costa/bursi.gspan'\n",
      "input_target_url='http://www.bioinf.uni-freiburg.de/~costa/bursi.target'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "vec=graph.Vectorizer(r=max_radius,d=max_distance)\n",
      "g_it=gspan.gspan_to_eden(input_data_url)\n",
      "X=vec.transform(g_it, n_jobs=1)\n",
      "\n",
      "print 'Instances: %d Features: %d with an avg of %d features per instance' % (X.shape[0], X.shape[1],  X.getnnz()/X.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 4337 Features: 1048577 with an avg of 553 features per instance\n",
        "CPU times: user 47.8 s, sys: 168 ms, total: 48 s\n",
        "Wall time: 48.1 s\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "vec=graph.Vectorizer(r=max_radius,d=max_distance)\n",
      "g_it=gspan.gspan_to_eden(input_data_url)\n",
      "X=vec.transform(g_it, n_jobs=4)\n",
      "\n",
      "print 'Instances: %d Features: %d with an avg of %d features per instance' % (X.shape[0], X.shape[1],  X.getnnz()/X.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 4337 Features: 1048577 with an avg of 553 features per instance\n",
        "CPU times: user 14.6 s, sys: 1.41 s, total: 16 s\n",
        "Wall time: 21.9 s\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Induce a predictor and evaluate its performance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#induce a predictive model\n",
      "predictor = SGDClassifier()\n",
      "#for a specific bioassay\n",
      "y=io.load_target(input_target_url)\n",
      "scores = cross_validation.cross_val_score(predictor, X, y,cv=10, scoring='roc_auc')\n",
      "print('AUC ROC: %.4f +- %.4f' % (np.mean(scores),np.std(scores)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "AUC ROC: 0.9076 +- 0.0139\n",
        "CPU times: user 1.85 s, sys: 11 ms, total: 1.86 s\n",
        "Wall time: 1.88 s\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    }
   ],
   "metadata": {}
  }
 ]
}