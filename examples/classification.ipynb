{
 "metadata": {
  "name": "",
  "signature": "sha256:2138ffe5f606574359f225636ba5b5dfcaa6bf32e7c74214469d852f0006d71a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden import graph\n",
      "from eden.util import eden_io\n",
      "from eden.converters import gspan"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn import cross_validation\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " help(graph.Vectorizer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Help on class Vectorizer in module eden.graph:\n",
        "\n",
        "class Vectorizer(__builtin__.object)\n",
        " |  Transforms labeled, weighted, nested graphs in sparse vectors.\n",
        " |  \n",
        " |  Methods defined here:\n",
        " |  \n",
        " |  __init__(self, r=3, d=3, min_r=0, min_d=0, nbits=20, normalization=True, inner_normalization=True, pure_neighborhood_features=False, discretization_size=0, discretization_dimension=1)\n",
        " |      Parameters\n",
        " |      ----------\n",
        " |      r : int \n",
        " |          The maximal radius size.\n",
        " |      \n",
        " |      d : int \n",
        " |          The maximal distance size.\n",
        " |      \n",
        " |      min_r : int \n",
        " |          The minimal radius size.\n",
        " |      \n",
        " |      min_d : int \n",
        " |          The minimal distance size.\n",
        " |      \n",
        " |      nbits : int \n",
        " |          The number of bits that defines the feature space size: |feature space|=2^nbits.\n",
        " |      \n",
        " |      normalization : bool \n",
        " |          If set the resulting feature vector will have unit euclidean norm.\n",
        " |      \n",
        " |      inner_normalization : bool \n",
        " |          If set the feature vector for a specific combination of the radius and \n",
        " |          distance size will have unit euclidean norm.\n",
        " |          When used together with the 'normalization' flag it will be applied first and \n",
        " |          then the resulting feature vector will be normalized.\n",
        " |      \n",
        " |      pure_neighborhood_features : bool \n",
        " |          If set additional features are going to be generated. \n",
        " |          These features are generated in a similar fashion as the base features, \n",
        " |          with the caveat that the first neighborhood is omitted.\n",
        " |          The purpose of these features is to allow vertices that have similar contexts to be \n",
        " |          matched, even when they are completely different. \n",
        " |      \n",
        " |      discretization_size : int\n",
        " |          Number of discretization levels for real vector labels.\n",
        " |          If 0 then treat all labels as strings. \n",
        " |      \n",
        " |      discretization_dimension : int\n",
        " |          Size of the discretized label vector.\n",
        " |  \n",
        " |  fit(self, G_list, n_jobs=1)\n",
        " |      Constructs an approximate explicit mapping of a kernel function on the data \n",
        " |      stored in the nodes of the graphs.\n",
        " |      \n",
        " |      Parameters\n",
        " |      ----------\n",
        " |      G_list : list of networkx graphs. \n",
        " |          The data.\n",
        " |      \n",
        " |      n_jobs : integer, optional\n",
        " |          Number of jobs to run in parallel (default 1).\n",
        " |          Use -1 to indicate the total number of CPUs available.\n",
        " |  \n",
        " |  fit_transform(self, G_list, n_jobs=1)\n",
        " |      Parameters\n",
        " |      ----------\n",
        " |      G_list : list of networkx graphs. \n",
        " |          The data.\n",
        " |      \n",
        " |      n_jobs : integer, optional\n",
        " |          Number of jobs to run in parallel (default 1).\n",
        " |          Use -1 to indicate the total number of CPUs available.\n",
        " |  \n",
        " |  transform(self, G_list, n_jobs=1)\n",
        " |      Transforms a list of networkx graphs into a Numpy csr sparse matrix \n",
        " |      (Compressed Sparse Row matrix).\n",
        " |      \n",
        " |      Parameters\n",
        " |      ----------\n",
        " |      G_list : list of networkx graphs. \n",
        " |          The data.\n",
        " |      \n",
        " |      n_jobs : integer, optional\n",
        " |          Number of jobs to run in parallel (default 1). \n",
        " |          Use -1 to indicate the total number of CPUs available.\n",
        " |  \n",
        " |  transform_iter(self, G_list)\n",
        " |      Transforms a list of networkx graphs into a Numpy csr sparse matrix \n",
        " |      (Compressed Sparse Row matrix) and returns one sparse row at a time.\n",
        " |      This is a generator.\n",
        " |  \n",
        " |  ----------------------------------------------------------------------\n",
        " |  Data descriptors defined here:\n",
        " |  \n",
        " |  __dict__\n",
        " |      dictionary for instance variables (if defined)\n",
        " |  \n",
        " |  __weakref__\n",
        " |      list of weak references to the object (if defined)\n",
        " |  \n",
        " |  ----------------------------------------------------------------------\n",
        " |  Data and other attributes defined here:\n",
        " |  \n",
        " |  __slotnames__ = []\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "help(eden_io.load_target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Help on function load_target in module eden.util.eden_io:\n",
        "\n",
        "load_target(name, input_type='url')\n",
        "    Return a numpy array of integers to be used as target vector.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    name : string\n",
        "        A pointer to the data source.\n",
        "    \n",
        "    input_type : ['url','file','string_file']\n",
        "        If type is 'url' then 'name' is interpreted as a URL pointing to a file.\n",
        "        If type is 'file' then 'name' is interpreted as a file name.\n",
        "        If type is 'string_file' then 'name' is interpreted as a file name for a file \n",
        "        that contains strings rather than integers. The set of strings are mapped to \n",
        "        unique increasing integers and the corresponding vector of integers is returned.\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Create Feature Representation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "input_data_url='http://www.bioinf.uni-freiburg.de/~costa/bursi.gspan'\n",
      "input_target_url='http://www.bioinf.uni-freiburg.de/~costa/bursi.target'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_radius=3\n",
      "min_radius=0\n",
      "max_distance=0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#single core processing\n",
      "vec=graph.Vectorizer(r=max_radius,d=max_distance, min_r=min_radius)\n",
      "g_it=gspan.gspan_to_eden(input_data_url)\n",
      "X=vec.transform(g_it, n_jobs=1)\n",
      "\n",
      "print 'Instances: %d Features: %d with an avg of %d features per instance' % (X.shape[0], X.shape[1],  X.getnnz()/X.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 4337 Features: 1048577 with an avg of 34 features per instance\n",
        "CPU times: user 18.1 s, sys: 19 ms, total: 18.1 s\n",
        "Wall time: 18.2 s\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#multi-core processing\n",
      "vec=graph.Vectorizer(r=max_radius,d=max_distance, min_r=min_radius)\n",
      "g_it=gspan.gspan_to_eden(input_data_url)\n",
      "X=vec.transform(g_it, n_jobs=-1)\n",
      "\n",
      "print 'Instances: %d Features: %d with an avg of %d features per instance' % (X.shape[0], X.shape[1],  X.getnnz()/X.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 4337 Features: 1048577 with an avg of 34 features per instance\n",
        "CPU times: user 13.3 s, sys: 285 ms, total: 13.5 s\n",
        "Wall time: 18.3 s\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Induce a predictor and evaluate its performance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#induce a predictive model\n",
      "predictor = SGDClassifier()\n",
      "#for a specific bioassay\n",
      "y=eden_io.load_target(input_target_url)\n",
      "scores = cross_validation.cross_val_score(predictor, X, y,cv=10, scoring='roc_auc')\n",
      "print('AUC ROC: %.4f +- %.4f' % (np.mean(scores),np.std(scores)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "AUC ROC: 0.8991 +- 0.0157\n",
        "CPU times: user 579 ms, sys: 8 ms, total: 587 ms\n",
        "Wall time: 593 ms\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Use only large features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_radius=3\n",
      "min_radius=3\n",
      "max_distance=0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#multi-core processing\n",
      "vec=graph.Vectorizer(r=max_radius,d=max_distance, min_r=min_radius)\n",
      "g_it=gspan.gspan_to_eden(input_data_url)\n",
      "X=vec.transform(g_it, n_jobs=-1)\n",
      "\n",
      "print 'Instances: %d Features: %d with an avg of %d features per instance' % (X.shape[0], X.shape[1],  X.getnnz()/X.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 4337 Features: 1048577 with an avg of 12 features per instance\n",
        "CPU times: user 12.8 s, sys: 272 ms, total: 13.1 s\n",
        "Wall time: 15.6 s\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#induce a predictive model\n",
      "predictor = SGDClassifier()\n",
      "#for a specific bioassay\n",
      "y=eden_io.load_target(input_target_url)\n",
      "scores = cross_validation.cross_val_score(predictor, X, y,cv=10, scoring='roc_auc')\n",
      "print('AUC ROC: %.4f +- %.4f' % (np.mean(scores),np.std(scores)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "AUC ROC: 0.8938 +- 0.0220\n",
        "CPU times: user 515 ms, sys: 8 ms, total: 523 ms\n",
        "Wall time: 534 ms\n"
       ]
      }
     ],
     "prompt_number": 59
    }
   ],
   "metadata": {}
  }
 ]
}