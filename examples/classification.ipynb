{
 "metadata": {
  "name": "",
  "signature": "sha256:8e6192867ad6ada9b136074c5d73df34d7f51a410725e6a6f3124fbd9b79c613"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden import graph\n",
      "from eden.util import eden_io\n",
      "from eden.converters import gspan"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn import cross_validation\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " help(graph.Vectorizer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Help on class Vectorizer in module eden.graph:\n",
        "\n",
        "class Vectorizer(__builtin__.object)\n",
        " |  Transforms labeled, weighted, nested graphs in sparse vectors.\n",
        " |  \n",
        " |  Methods defined here:\n",
        " |  \n",
        " |  __init__(self, r=3, d=3, nbits=20, normalization=True, inner_normalization=True, pure_neighborhood_features=False, approximate_kernel_mapper_dict={}, hasher_dict={})\n",
        " |      Parameters\n",
        " |      ----------\n",
        " |      r : int \n",
        " |          The radius size.\n",
        " |      \n",
        " |      d : int \n",
        " |          The distance size.\n",
        " |      \n",
        " |      nbits : int \n",
        " |          The number of bits that defines the feature space size: |feature space|=2^nbits.\n",
        " |      \n",
        " |      normalization : bool \n",
        " |          If set the resulting feature vector will have unit euclidean norm.\n",
        " |      \n",
        " |      inner_normalization : bool \n",
        " |          If set the feature vector for a specific combination of the radius and \n",
        " |          distance size will have unit euclidean norm.\n",
        " |          When used together with the 'normalization' flag it will be applied first and \n",
        " |          then the resulting feature vector will be normalized.\n",
        " |      \n",
        " |      pure_neighborhood_features : bool \n",
        " |          If set additional features are going to be generated. \n",
        " |          These features are generated in a similar fashion as the base features, \n",
        " |          with the caveat that the first neighborhood is omitted.\n",
        " |          The purpose of these features is to allow vertices that have similar contexts to be \n",
        " |          matched, even when they are completely different. \n",
        " |      \n",
        " |      approximate_kernel_mapper_dict : list of approximate kernel mappers. \n",
        " |          The key matches the 'type' of nodes. The assocaited value is \n",
        " |          a pair (kernel approximation callable, parameters dictionary) that can work on the\n",
        " |          matrix of all 'label' extracted from the nodes.\n",
        " |          The 'approximate_kernel_mapper_dict' dictionary specifies the appropriate approximate \n",
        " |          kernel mapping strategy for different node 'classes'. \n",
        " |      \n",
        " |      hasher_dict : list of locality sensitive hashing (LSH) functions.\n",
        " |          The key matches the 'type' of nodes. The assocaited value is \n",
        " |          a pair (LSH callable, parameters dictionary) that can work on the matrix of the \n",
        " |          approximated 'label' extracted from nodes and processed by the kernel \n",
        " |          approximate mappers.\n",
        " |          The 'hasher_dict' specifies the locality sensitive hashing strategy to discretize \n",
        " |          the resulting approximate kernel mapping.\n",
        " |  \n",
        " |  fit(self, G_list, n_jobs=1)\n",
        " |      Constructs an approximate explicit mapping of a kernel function on the data \n",
        " |      stored in the nodes of the graphs.\n",
        " |      \n",
        " |      Parameters\n",
        " |      ----------\n",
        " |      G_list : list of networkx graphs. \n",
        " |          The data.\n",
        " |      \n",
        " |      n_jobs : integer, optional\n",
        " |          Number of jobs to run in parallel (default 1).\n",
        " |          Use -1 to indicate the total number of CPUs available.\n",
        " |  \n",
        " |  fit_transform(self, G_list, n_jobs=1)\n",
        " |      Constructs an approximate explicit mapping of a kernel function on the data \n",
        " |      stored in the nodes of the graphs and then transforms a list of networkx graphs \n",
        " |      into a Numpy csr sparse matrix (Compressed Sparse Row matrix).\n",
        " |      \n",
        " |      The 'approximate_kernel_mapper_dict' dictionary specifies the appropriate approximate kernel mapping \n",
        " |      strategy for different node 'classes'. The 'hasher_dict' specifies the locality sensitive \n",
        " |      hashing strategy to discretize the resulting approximate kernel mapping.\n",
        " |      \n",
        " |      Parameters\n",
        " |      ----------\n",
        " |      G_list : list of networkx graphs. \n",
        " |          The data.\n",
        " |      \n",
        " |      n_jobs : integer, optional\n",
        " |          Number of jobs to run in parallel (default 1).\n",
        " |          Use -1 to indicate the total number of CPUs available.\n",
        " |  \n",
        " |  transform(self, G_list, n_jobs=1)\n",
        " |      Transforms a list of networkx graphs into a Numpy csr sparse matrix \n",
        " |      (Compressed Sparse Row matrix).\n",
        " |      \n",
        " |      Parameters\n",
        " |      ----------\n",
        " |      G_list : list of networkx graphs. \n",
        " |          The data.\n",
        " |      \n",
        " |      n_jobs : integer, optional\n",
        " |          Number of jobs to run in parallel (default 1). \n",
        " |          Use -1 to indicate the total number of CPUs available.\n",
        " |  \n",
        " |  transform_iter(self, G_list)\n",
        " |      Transforms a list of networkx graphs into a Numpy csr sparse matrix \n",
        " |      (Compressed Sparse Row matrix) and returns one sparse row at a time.\n",
        " |      This is a generator.\n",
        " |  \n",
        " |  ----------------------------------------------------------------------\n",
        " |  Data descriptors defined here:\n",
        " |  \n",
        " |  __dict__\n",
        " |      dictionary for instance variables (if defined)\n",
        " |  \n",
        " |  __weakref__\n",
        " |      list of weak references to the object (if defined)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "help(eden_io.load_target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Help on function load_target in module eden.util.eden_io:\n",
        "\n",
        "load_target(name, input_type='url')\n",
        "    Return a numpy array of integers to be used as target vector.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    name : string\n",
        "        A pointer to the data source.\n",
        "    \n",
        "    input_type : ['url','file','string_file']\n",
        "        If type is 'url' then 'name' is interpreted as a URL pointing to a file.\n",
        "        If type is 'file' then 'name' is interpreted as a file name.\n",
        "        If type is 'string_file' then 'name' is interpreted as a file name for a file \n",
        "        that contains strings rather than integers. The set of strings are mapped to \n",
        "        unique increasing integers and the corresponding vector of integers is returned.\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Create Feature Representation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_radius=3\n",
      "max_distance=5\n",
      "input_data_url='http://www.bioinf.uni-freiburg.de/~costa/bursi.gspan'\n",
      "input_target_url='http://www.bioinf.uni-freiburg.de/~costa/bursi.target'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#single core processing\n",
      "vec=graph.Vectorizer(r=max_radius,d=max_distance)\n",
      "g_it=gspan.gspan_to_eden(input_data_url)\n",
      "X=vec.transform(g_it, n_jobs=1)\n",
      "\n",
      "print 'Instances: %d Features: %d with an avg of %d features per instance' % (X.shape[0], X.shape[1],  X.getnnz()/X.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 4337 Features: 1048577 with an avg of 477 features per instance\n",
        "CPU times: user 1min 41s, sys: 345 ms, total: 1min 41s\n",
        "Wall time: 1min 41s\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#multi-core processing\n",
      "vec=graph.Vectorizer(r=max_radius,d=max_distance)\n",
      "g_it=gspan.gspan_to_eden(input_data_url)\n",
      "X=vec.transform(g_it, n_jobs=-1)\n",
      "\n",
      "print 'Instances: %d Features: %d with an avg of %d features per instance' % (X.shape[0], X.shape[1],  X.getnnz()/X.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 4337 Features: 1048577 with an avg of 477 features per instance\n",
        "CPU times: user 20.6 s, sys: 599 ms, total: 21.2 s\n",
        "Wall time: 1min 2s\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Induce a predictor and evaluate its performance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#induce a predictive model\n",
      "predictor = SGDClassifier()\n",
      "#for a specific bioassay\n",
      "y=eden_io.load_target(input_target_url)\n",
      "scores = cross_validation.cross_val_score(predictor, X, y,cv=10, scoring='roc_auc')\n",
      "print('AUC ROC: %.4f +- %.4f' % (np.mean(scores),np.std(scores)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "AUC ROC: 0.9049 +- 0.0140\n",
        "CPU times: user 3.09 s, sys: 9 ms, total: 3.1 s\n",
        "Wall time: 3.11 s\n"
       ]
      }
     ],
     "prompt_number": 8
    }
   ],
   "metadata": {}
  }
 ]
}